"""
æµ‹è¯• DocumentEditNode çš„ LLM è°ƒç”¨å’Œ JSON è§£æ
"""

import asyncio
import json
from unittest.mock import Mock, AsyncMock, patch
import sys
import os
import pytest

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from gtplanner.agent.subflows.document_edit.nodes.document_edit_node import DocumentEditNode


def create_mock_response(content: str):
    """åˆ›å»ºæ¨¡æ‹Ÿçš„ OpenAI å“åº”"""
    mock_choice = Mock()
    mock_choice.message.content = content
    
    mock_response = Mock()
    mock_response.choices = [mock_choice]
    
    return mock_response


@pytest.mark.asyncio
async def test_normal_json():
    """æµ‹è¯•åœºæ™¯1: æ­£å¸¸çš„ JSON å“åº”"""
    print("\n" + "="*80)
    print("æµ‹è¯•åœºæ™¯ 1: æ­£å¸¸çš„ JSON å“åº”")
    print("="*80)
    
    node = DocumentEditNode()
    
    # æ¨¡æ‹Ÿ LLM è¿”å›æ­£å¸¸çš„ JSON
    normal_json = {
        "edits": [
            {
                "search": "### 3.2 æ•°æ®å­˜å‚¨\n\nä½¿ç”¨ PostgreSQL ä½œä¸ºä¸»æ•°æ®åº“ã€‚",
                "replace": "### 3.2 æ•°æ®å­˜å‚¨\n\nä½¿ç”¨ PostgreSQL ä½œä¸ºä¸»æ•°æ®åº“ï¼Œé…åˆ Redis ä½œä¸ºç¼“å­˜å±‚ã€‚",
                "reason": "æ·»åŠ  Redis ç¼“å­˜å±‚"
            }
        ],
        "summary": "åœ¨æ•°æ®å­˜å‚¨ç« èŠ‚æ·»åŠ äº† Redis ç¼“å­˜å±‚"
    }
    
    mock_response = create_mock_response(json.dumps(normal_json, ensure_ascii=False))
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    prep_result = {
        "success": True,
        "document_type": "design",
        "document_content": "### 3.2 æ•°æ®å­˜å‚¨\n\nä½¿ç”¨ PostgreSQL ä½œä¸ºä¸»æ•°æ®åº“ã€‚\n\nå…¶ä»–å†…å®¹...",
        "document_filename": "design.md",
        "edit_instructions": "æ·»åŠ  Redis ç¼“å­˜å±‚è¯´æ˜",
        "streaming_session": None,
        "language": "zh"
    }
    
    # Mock OpenAI client
    with patch.object(node.openai_client, 'chat_completion', new_callable=AsyncMock) as mock_chat:
        mock_chat.return_value = mock_response
        
        result = await node.exec_async(prep_result)
        
        print(f"âœ… æµ‹è¯•ç»“æœ: {result.get('success')}")
        print(f"ğŸ“ ç”Ÿæˆçš„ç¼–è¾‘æ•°é‡: {len(result.get('edits', []))}")
        print(f"ğŸ“‹ æ‘˜è¦: {result.get('summary')}")
        
        assert result["success"] == True
        assert len(result["edits"]) == 1
        print("\nâœ… æµ‹è¯•åœºæ™¯ 1 é€šè¿‡ï¼")


@pytest.mark.asyncio
async def test_markdown_wrapped_json():
    """æµ‹è¯•åœºæ™¯2: Markdown ä»£ç å—åŒ…è£¹çš„ JSON"""
    print("\n" + "="*80)
    print("æµ‹è¯•åœºæ™¯ 2: Markdown ä»£ç å—åŒ…è£¹çš„ JSON (```json)")
    print("="*80)
    
    node = DocumentEditNode()
    
    # æ¨¡æ‹Ÿ LLM è¿”å› Markdown åŒ…è£¹çš„ JSON
    normal_json = {
        "edits": [
            {
                "search": "### æµ‹è¯•",
                "replace": "### æµ‹è¯•ä¿®æ”¹",
                "reason": "æµ‹è¯•ä¿®æ”¹"
            }
        ],
        "summary": "æµ‹è¯•ä¿®æ”¹"
    }
    
    # ç”¨ ```json åŒ…è£¹
    wrapped_content = f"```json\n{json.dumps(normal_json, ensure_ascii=False, indent=2)}\n```"
    mock_response = create_mock_response(wrapped_content)
    
    prep_result = {
        "success": True,
        "document_type": "design",
        "document_content": "### æµ‹è¯•\n\nå†…å®¹...",
        "document_filename": "design.md",
        "edit_instructions": "ä¿®æ”¹æ ‡é¢˜",
        "streaming_session": None,
        "language": "zh"
    }
    
    with patch.object(node.openai_client, 'chat_completion', new_callable=AsyncMock) as mock_chat:
        mock_chat.return_value = mock_response
        
        result = await node.exec_async(prep_result)
        
        print(f"âœ… æµ‹è¯•ç»“æœ: {result.get('success')}")
        print(f"ğŸ“ ç”Ÿæˆçš„ç¼–è¾‘æ•°é‡: {len(result.get('edits', []))}")
        
        assert result["success"] == True
        assert len(result["edits"]) == 1
        print("\nâœ… æµ‹è¯•åœºæ™¯ 2 é€šè¿‡ï¼")


@pytest.mark.asyncio
async def test_plain_markdown_wrapped():
    """æµ‹è¯•åœºæ™¯3: æ™®é€š Markdown ä»£ç å—åŒ…è£¹ (```)"""
    print("\n" + "="*80)
    print("æµ‹è¯•åœºæ™¯ 3: æ™®é€š Markdown ä»£ç å—åŒ…è£¹ (```)")
    print("="*80)
    
    node = DocumentEditNode()
    
    normal_json = {
        "edits": [
            {
                "search": "æµ‹è¯•å†…å®¹",
                "replace": "ä¿®æ”¹åçš„å†…å®¹",
                "reason": "æµ‹è¯•"
            }
        ],
        "summary": "æµ‹è¯•æ‘˜è¦"
    }
    
    # ç”¨æ™®é€š ``` åŒ…è£¹
    wrapped_content = f"```\n{json.dumps(normal_json, ensure_ascii=False)}\n```"
    mock_response = create_mock_response(wrapped_content)
    
    prep_result = {
        "success": True,
        "document_type": "design",
        "document_content": "æµ‹è¯•å†…å®¹\n\næ›´å¤šå†…å®¹...",
        "document_filename": "design.md",
        "edit_instructions": "ä¿®æ”¹å†…å®¹",
        "streaming_session": None,
        "language": "zh"
    }
    
    with patch.object(node.openai_client, 'chat_completion', new_callable=AsyncMock) as mock_chat:
        mock_chat.return_value = mock_response
        
        result = await node.exec_async(prep_result)
        
        print(f"âœ… æµ‹è¯•ç»“æœ: {result.get('success')}")
        print(f"ğŸ“ ç”Ÿæˆçš„ç¼–è¾‘æ•°é‡: {len(result.get('edits', []))}")
        
        assert result["success"] == True
        assert len(result["edits"]) == 1
        print("\nâœ… æµ‹è¯•åœºæ™¯ 3 é€šè¿‡ï¼")


@pytest.mark.asyncio
async def test_empty_edits():
    """æµ‹è¯•åœºæ™¯4: ç©ºçš„ç¼–è¾‘åˆ—è¡¨"""
    print("\n" + "="*80)
    print("æµ‹è¯•åœºæ™¯ 4: LLM è¿”å›ç©ºçš„ç¼–è¾‘åˆ—è¡¨")
    print("="*80)
    
    node = DocumentEditNode()
    
    empty_json = {
        "edits": [],
        "summary": "æ²¡æœ‰éœ€è¦ä¿®æ”¹çš„å†…å®¹"
    }
    
    mock_response = create_mock_response(json.dumps(empty_json))
    
    prep_result = {
        "success": True,
        "document_type": "design",
        "document_content": "æµ‹è¯•å†…å®¹",
        "document_filename": "design.md",
        "edit_instructions": "ä¿®æ”¹",
        "streaming_session": None,
        "language": "zh"
    }
    
    with patch.object(node.openai_client, 'chat_completion', new_callable=AsyncMock) as mock_chat:
        mock_chat.return_value = mock_response
        
        result = await node.exec_async(prep_result)
        
        print(f"âœ… æµ‹è¯•ç»“æœ: {result.get('success')}")
        print(f"âŒ é”™è¯¯ä¿¡æ¯: {result.get('error')}")
        
        assert result["success"] == False
        assert "did not generate any edits" in result["error"]
        print("\nâœ… æµ‹è¯•åœºæ™¯ 4 é€šè¿‡ï¼ˆæ­£ç¡®å¤„ç†ç©ºç»“æœï¼‰ï¼")


@pytest.mark.asyncio
async def test_invalid_json():
    """æµ‹è¯•åœºæ™¯5: æ— æ•ˆçš„ JSON"""
    print("\n" + "="*80)
    print("æµ‹è¯•åœºæ™¯ 5: LLM è¿”å›æ— æ•ˆçš„ JSON")
    print("="*80)
    
    node = DocumentEditNode()
    
    # è¿”å›æ— æ•ˆçš„ JSON
    invalid_content = "è¿™ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ JSON å­—ç¬¦ä¸²"
    mock_response = create_mock_response(invalid_content)
    
    prep_result = {
        "success": True,
        "document_type": "design",
        "document_content": "æµ‹è¯•å†…å®¹",
        "document_filename": "design.md",
        "edit_instructions": "ä¿®æ”¹",
        "streaming_session": None,
        "language": "zh"
    }
    
    with patch.object(node.openai_client, 'chat_completion', new_callable=AsyncMock) as mock_chat:
        mock_chat.return_value = mock_response
        
        result = await node.exec_async(prep_result)
        
        print(f"âœ… æµ‹è¯•ç»“æœ: {result.get('success')}")
        print(f"âŒ é”™è¯¯ä¿¡æ¯: {result.get('error')}")
        print(f"ğŸ“„ åŸå§‹å“åº”: {result.get('raw_response', 'N/A')[:100]}")
        
        assert result["success"] == False
        assert "Failed to parse LLM response" in result["error"]
        assert "raw_response" in result  # åº”è¯¥åŒ…å«åŸå§‹å“åº”
        print("\nâœ… æµ‹è¯•åœºæ™¯ 5 é€šè¿‡ï¼ˆæ­£ç¡®å¤„ç†è§£æé”™è¯¯ï¼‰ï¼")


@pytest.mark.asyncio
async def test_validation_failure():
    """æµ‹è¯•åœºæ™¯6: ç¼–è¾‘éªŒè¯å¤±è´¥ï¼ˆsearch æ–‡æœ¬ä¸å­˜åœ¨ï¼‰"""
    print("\n" + "="*80)
    print("æµ‹è¯•åœºæ™¯ 6: ç¼–è¾‘éªŒè¯å¤±è´¥ï¼ˆsearch æ–‡æœ¬åœ¨æ–‡æ¡£ä¸­ä¸å­˜åœ¨ï¼‰")
    print("="*80)
    
    node = DocumentEditNode()
    
    # LLM è¿”å›çš„ search æ–‡æœ¬ä¸åœ¨åŸæ–‡æ¡£ä¸­
    invalid_edit_json = {
        "edits": [
            {
                "search": "è¿™æ®µæ–‡æœ¬ä¸å­˜åœ¨äºæ–‡æ¡£ä¸­",
                "replace": "æ›¿æ¢å†…å®¹",
                "reason": "æµ‹è¯•"
            }
        ],
        "summary": "æµ‹è¯•ç¼–è¾‘"
    }
    
    mock_response = create_mock_response(json.dumps(invalid_edit_json, ensure_ascii=False))
    
    prep_result = {
        "success": True,
        "document_type": "design",
        "document_content": "### å®é™…çš„æ–‡æ¡£å†…å®¹\n\nè¿™é‡Œæ˜¯çœŸå®çš„å†…å®¹ã€‚",
        "document_filename": "design.md",
        "edit_instructions": "ä¿®æ”¹",
        "streaming_session": None,
        "language": "zh"
    }
    
    with patch.object(node.openai_client, 'chat_completion', new_callable=AsyncMock) as mock_chat:
        mock_chat.return_value = mock_response
        
        result = await node.exec_async(prep_result)
        
        print(f"âœ… æµ‹è¯•ç»“æœ: {result.get('success')}")
        print(f"âŒ é”™è¯¯ä¿¡æ¯: {result.get('error')}")
        print(f"ğŸ“‹ éªŒè¯é”™è¯¯: {result.get('validation_errors', [])}")
        
        assert result["success"] == False
        assert "Edit validation failed" in result["error"]
        assert len(result.get("validation_errors", [])) > 0
        print("\nâœ… æµ‹è¯•åœºæ™¯ 6 é€šè¿‡ï¼ˆæ­£ç¡®å¤„ç†éªŒè¯é”™è¯¯ï¼‰ï¼")


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸ§ª" * 40)
    print("å¼€å§‹æµ‹è¯• DocumentEditNode çš„ LLM è°ƒç”¨å’Œ JSON è§£æ")
    print("ğŸ§ª" * 40)
    
    tests = [
        ("æ­£å¸¸ JSON", test_normal_json),
        ("Markdown ```json åŒ…è£¹", test_markdown_wrapped_json),
        ("Markdown ``` åŒ…è£¹", test_plain_markdown_wrapped),
        ("ç©ºç¼–è¾‘åˆ—è¡¨", test_empty_edits),
        ("æ— æ•ˆ JSON", test_invalid_json),
        ("éªŒè¯å¤±è´¥", test_validation_failure),
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        try:
            await test_func()
            passed += 1
        except AssertionError as e:
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {test_name}")
            print(f"é”™è¯¯: {str(e)}")
            failed += 1
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•å‡ºé”™: {test_name}")
            print(f"å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
            failed += 1
    
    print("\n" + "="*80)
    print(f"æµ‹è¯•å®Œæˆï¼é€šè¿‡: {passed}/{len(tests)}, å¤±è´¥: {failed}/{len(tests)}")
    print("="*80)
    
    if failed == 0:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼edit_document å·¥å…·å·²ä¿®å¤æˆåŠŸï¼")
    else:
        print(f"âŒ æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¿®å¤ã€‚")
    
    return failed == 0


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)

