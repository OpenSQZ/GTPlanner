"""
HTTPè¿žæŽ¥æ± æ€§èƒ½æµ‹è¯•

æµ‹è¯•HTTPè¿žæŽ¥æ± çš„æ€§èƒ½æ”¹è¿›æ•ˆæžœï¼ŒåŒ…æ‹¬ï¼š
1. è¿žæŽ¥å¤ç”¨æ•ˆæžœ
2. å¹¶å‘è¯·æ±‚æ€§èƒ½
3. ç¼“å­˜å‘½ä¸­çŽ‡
4. é‡è¯•æœºåˆ¶æ•ˆæžœ
"""

import asyncio
import time
import statistics
from typing import List, Dict, Any
import pytest

from utils.http_pool_manager import get_http_pool, HTTPPoolManager, ConnectionPoolConfig, CacheConfig
from utils.openai_client import get_openai_client


class HTTPPerformanceTester:
    """HTTPæ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.results: Dict[str, Any] = {}
    
    async def test_connection_reuse(self, num_requests: int = 10) -> Dict[str, Any]:
        """æµ‹è¯•è¿žæŽ¥å¤ç”¨æ•ˆæžœ"""
        print(f"ðŸ”„ æµ‹è¯•è¿žæŽ¥å¤ç”¨ ({num_requests} ä¸ªè¯·æ±‚)...")
        
        pool = await get_http_pool()
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # å‘é€å¤šä¸ªè¯·æ±‚åˆ°åŒä¸€ä¸ªä¸»æœº
        tasks = []
        for i in range(num_requests):
            task = pool.request(
                "GET",
                "https://httpbin.org/delay/0.1",
                cache_key=f"test_reuse_{i}"  # ä¸åŒçš„ç¼“å­˜é”®é¿å…ç¼“å­˜å½±å“
            )
            tasks.append(task)
        
        # å¹¶å‘æ‰§è¡Œ
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        total_time = time.time() - start_time
        
        # åˆ†æžç»“æžœ
        successful_requests = sum(1 for r in responses if isinstance(r, dict) and r.get("success"))
        avg_time_per_request = total_time / num_requests
        
        stats = pool.get_stats()
        
        result = {
            "test_name": "connection_reuse",
            "num_requests": num_requests,
            "successful_requests": successful_requests,
            "total_time": total_time,
            "avg_time_per_request": avg_time_per_request,
            "requests_per_second": num_requests / total_time,
            "pool_stats": stats
        }
        
        print(f"  âœ… æˆåŠŸè¯·æ±‚: {successful_requests}/{num_requests}")
        print(f"  â±ï¸ æ€»æ—¶é—´: {total_time:.2f}s")
        print(f"  ðŸ“Š å¹³å‡æ¯è¯·æ±‚: {avg_time_per_request:.3f}s")
        print(f"  ðŸš€ QPS: {result['requests_per_second']:.2f}")
        
        return result
    
    async def test_cache_performance(self, num_requests: int = 20) -> Dict[str, Any]:
        """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
        print(f"ðŸ’¾ æµ‹è¯•ç¼“å­˜æ€§èƒ½ ({num_requests} ä¸ªè¯·æ±‚)...")
        
        # åˆ›å»ºå¯ç”¨ç¼“å­˜çš„è¿žæŽ¥æ± 
        cache_config = CacheConfig(enabled=True, max_size=100, ttl_seconds=60)
        pool = HTTPPoolManager(cache_config=cache_config)
        await pool._initialize()
        
        # ç¬¬ä¸€è½®ï¼šå¡«å……ç¼“å­˜
        cache_key = "test_cache_key"
        start_time = time.time()
        
        first_response = await pool.request(
            "GET",
            "https://httpbin.org/delay/0.5",
            cache_key=cache_key
        )
        first_request_time = time.time() - start_time
        
        # ç¬¬äºŒè½®ï¼šä»Žç¼“å­˜è¯»å–
        cache_start_time = time.time()
        tasks = []
        for i in range(num_requests - 1):
            task = pool.request(
                "GET",
                "https://httpbin.org/delay/0.5",
                cache_key=cache_key
            )
            tasks.append(task)
        
        cached_responses = await asyncio.gather(*tasks, return_exceptions=True)
        cache_total_time = time.time() - cache_start_time
        
        stats = pool.get_stats()
        
        result = {
            "test_name": "cache_performance",
            "first_request_time": first_request_time,
            "cached_requests_time": cache_total_time,
            "cache_hit_rate": stats.get("cache_hit_rate", 0),
            "cache_hits": stats.get("cache_hits", 0),
            "cache_misses": stats.get("cache_misses", 0),
            "speedup_factor": first_request_time / (cache_total_time / (num_requests - 1)) if cache_total_time > 0 else 0
        }
        
        print(f"  ðŸŽ¯ é¦–æ¬¡è¯·æ±‚æ—¶é—´: {first_request_time:.3f}s")
        print(f"  âš¡ ç¼“å­˜è¯·æ±‚å¹³å‡æ—¶é—´: {cache_total_time / (num_requests - 1):.3f}s")
        print(f"  ðŸ“ˆ ç¼“å­˜å‘½ä¸­çŽ‡: {result['cache_hit_rate']:.2%}")
        print(f"  ðŸš€ åŠ é€Ÿå€æ•°: {result['speedup_factor']:.1f}x")
        
        await pool.close()
        return result
    
    async def test_concurrent_performance(self, num_concurrent: int = 10) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶å‘æ€§èƒ½"""
        print(f"âš¡ æµ‹è¯•å¹¶å‘æ€§èƒ½ ({num_concurrent} ä¸ªå¹¶å‘è¯·æ±‚)...")
        
        pool = await get_http_pool()
        
        # å¹¶å‘è¯·æ±‚æµ‹è¯•
        start_time = time.time()
        
        tasks = []
        for i in range(num_concurrent):
            task = pool.request(
                "GET",
                f"https://httpbin.org/delay/0.2",
                cache_key=f"concurrent_test_{i}"
            )
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        total_time = time.time() - start_time
        
        # åˆ†æžå“åº”æ—¶é—´
        response_times = []
        successful_requests = 0
        
        for response in responses:
            if isinstance(response, dict) and response.get("success"):
                successful_requests += 1
                response_times.append(response.get("execution_time", 0))
        
        stats = pool.get_stats()
        
        result = {
            "test_name": "concurrent_performance",
            "num_concurrent": num_concurrent,
            "successful_requests": successful_requests,
            "total_time": total_time,
            "avg_response_time": statistics.mean(response_times) if response_times else 0,
            "median_response_time": statistics.median(response_times) if response_times else 0,
            "max_response_time": max(response_times) if response_times else 0,
            "min_response_time": min(response_times) if response_times else 0,
            "pool_stats": stats
        }
        
        print(f"  âœ… æˆåŠŸè¯·æ±‚: {successful_requests}/{num_concurrent}")
        print(f"  â±ï¸ æ€»æ—¶é—´: {total_time:.2f}s")
        print(f"  ðŸ“Š å¹³å‡å“åº”æ—¶é—´: {result['avg_response_time']:.3f}s")
        print(f"  ðŸ“ˆ ä¸­ä½æ•°å“åº”æ—¶é—´: {result['median_response_time']:.3f}s")
        
        return result
    
    async def test_retry_mechanism(self) -> Dict[str, Any]:
        """æµ‹è¯•é‡è¯•æœºåˆ¶"""
        print("ðŸ”„ æµ‹è¯•é‡è¯•æœºåˆ¶...")
        
        pool = await get_http_pool()
        
        # æµ‹è¯•å¯¹å¤±è´¥è¯·æ±‚çš„é‡è¯•
        start_time = time.time()
        
        # ä½¿ç”¨ä¸€ä¸ªä¼šé—´æ­‡æ€§å¤±è´¥çš„ç«¯ç‚¹
        response = await pool.request(
            "GET",
            "https://httpbin.org/status/500",  # æ€»æ˜¯è¿”å›ž500é”™è¯¯
            cache_key="retry_test"
        )
        
        total_time = time.time() - start_time
        
        stats = pool.get_stats()
        
        result = {
            "test_name": "retry_mechanism",
            "response_success": response.get("success", False),
            "attempts": response.get("attempts", 1),
            "total_time": total_time,
            "retry_attempts": stats.get("retry_attempts", 0),
            "failed_requests": stats.get("failed_requests", 0)
        }
        
        print(f"  ðŸŽ¯ å“åº”æˆåŠŸ: {result['response_success']}")
        print(f"  ðŸ”„ å°è¯•æ¬¡æ•°: {result['attempts']}")
        print(f"  â±ï¸ æ€»æ—¶é—´: {total_time:.2f}s")
        
        return result
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•"""
        print("ðŸš€ å¼€å§‹HTTPè¿žæŽ¥æ± æ€§èƒ½æµ‹è¯•...")
        print("=" * 50)
        
        all_results = {}
        
        try:
            # 1. è¿žæŽ¥å¤ç”¨æµ‹è¯•
            all_results["connection_reuse"] = await self.test_connection_reuse(10)
            print()
            
            # 2. ç¼“å­˜æ€§èƒ½æµ‹è¯•
            all_results["cache_performance"] = await self.test_cache_performance(10)
            print()
            
            # 3. å¹¶å‘æ€§èƒ½æµ‹è¯•
            all_results["concurrent_performance"] = await self.test_concurrent_performance(5)
            print()
            
            # 4. é‡è¯•æœºåˆ¶æµ‹è¯•
            all_results["retry_mechanism"] = await self.test_retry_mechanism()
            print()
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯: {e}")
            all_results["error"] = str(e)
        
        print("=" * 50)
        print("ðŸ“Š æ€§èƒ½æµ‹è¯•æ€»ç»“:")
        
        for test_name, result in all_results.items():
            if isinstance(result, dict) and "test_name" in result:
                print(f"  {test_name}: âœ…")
            else:
                print(f"  {test_name}: âŒ")
        
        return all_results


@pytest.mark.asyncio
async def test_http_pool_performance():
    """pytestæµ‹è¯•å‡½æ•°"""
    tester = HTTPPerformanceTester()
    results = await tester.run_all_tests()
    
    # éªŒè¯åŸºæœ¬æ€§èƒ½æŒ‡æ ‡
    assert "connection_reuse" in results
    assert "cache_performance" in results
    assert "concurrent_performance" in results
    
    # éªŒè¯è¿žæŽ¥å¤ç”¨æ•ˆæžœ
    reuse_result = results["connection_reuse"]
    assert reuse_result["successful_requests"] > 0
    assert reuse_result["requests_per_second"] > 1  # è‡³å°‘1 QPS
    
    # éªŒè¯ç¼“å­˜æ•ˆæžœ
    cache_result = results["cache_performance"]
    assert cache_result["cache_hit_rate"] > 0.5  # è‡³å°‘50%å‘½ä¸­çŽ‡
    assert cache_result["speedup_factor"] > 1  # æœ‰åŠ é€Ÿæ•ˆæžœ


if __name__ == "__main__":
    async def main():
        tester = HTTPPerformanceTester()
        await tester.run_all_tests()
    
    asyncio.run(main())
