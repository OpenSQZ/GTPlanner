"""
é˜¶æ®µä¸€æ ¸å¿ƒç»„ä»¶æµ‹è¯•

æµ‹è¯•éªŒè¯ç³»ç»Ÿçš„æ ¸å¿ƒæ¥å£ã€æ•°æ®ç»“æ„å’Œé…ç½®ç®¡ç†ã€‚
"""

import pytest
import time
from datetime import datetime
from typing import Dict, Any

from agent.validation.core.interfaces import ValidatorPriority
from agent.validation.core.validation_context import ValidationContext, ValidationMode
from agent.validation.core.validation_result import (
    ValidationResult, ValidationError, ValidationStatus, 
    ValidationSeverity, ValidationMetrics
)
from agent.validation.core.base_validator import BaseValidator
from agent.validation.config.validation_config import ValidationConfig, ValidatorConfig


class TestValidationContext:
    """æµ‹è¯•éªŒè¯ä¸Šä¸‹æ–‡"""
    
    def test_create_basic_context(self):
        """æµ‹è¯•åŸºæœ¬ä¸Šä¸‹æ–‡åˆ›å»º"""
        context = ValidationContext(
            request_data={"test": "data"},
            validation_mode=ValidationMode.STRICT,
            request_path="/api/test"
        )
        
        assert context.request_data == {"test": "data"}
        assert context.validation_mode == ValidationMode.STRICT
        assert context.request_path == "/api/test"
        assert context.validation_start_time is not None
        assert context.get_execution_time() >= 0
    
    def test_context_for_testing(self):
        """æµ‹è¯•åˆ›å»ºç”¨äºæµ‹è¯•çš„ä¸Šä¸‹æ–‡"""
        context = ValidationContext.create_for_testing(
            request_data={"message": "hello"},
            validation_mode=ValidationMode.LENIENT
        )
        
        assert context.request_data == {"message": "hello"}
        assert context.validation_mode == ValidationMode.LENIENT
        assert context.request_method == "POST"
        assert context.request_path == "/api/test"
        assert not context.enable_cache  # æµ‹è¯•æ—¶é»˜è®¤ä¸å¯ç”¨ç¼“å­˜
    
    def test_should_skip_validator(self):
        """æµ‹è¯•éªŒè¯å™¨è·³è¿‡é€»è¾‘"""
        context = ValidationContext.create_for_testing(
            skip_validators=["validator1"],
            enabled_validators=["validator2", "validator3"]
        )
        
        assert context.should_skip_validator("validator1")  # åœ¨è·³è¿‡åˆ—è¡¨ä¸­
        assert not context.should_skip_validator("validator2")  # åœ¨å¯ç”¨åˆ—è¡¨ä¸­
        assert context.should_skip_validator("validator4")  # ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­
    
    def test_language_preference(self):
        """æµ‹è¯•è¯­è¨€åå¥½è·å–"""
        context = ValidationContext.create_for_testing(
            language="zh",
            supported_languages=["en", "zh", "ja"]
        )
        
        assert context.get_language_preference() == "zh"
        
        # æµ‹è¯•æ£€æµ‹åˆ°çš„è¯­è¨€
        context.language = None
        context.detected_language = "ja"
        assert context.get_language_preference() == "ja"
        
        # æµ‹è¯•é»˜è®¤è¯­è¨€
        context.detected_language = None
        assert context.get_language_preference() == "en"
    
    def test_context_summary(self):
        """æµ‹è¯•ä¸Šä¸‹æ–‡æ‘˜è¦"""
        context = ValidationContext.create_for_testing(
            request_data={"test": "data"}
        )
        
        summary = context.to_summary()
        assert "ValidationContext" in summary
        assert context.request_id in summary
        assert "POST" in summary


class TestValidationResult:
    """æµ‹è¯•éªŒè¯ç»“æœ"""
    
    def test_create_success_result(self):
        """æµ‹è¯•åˆ›å»ºæˆåŠŸç»“æœ"""
        result = ValidationResult.create_success(
            metadata={"test": "meta"},
            request_id="test_request"
        )
        
        assert result.status == ValidationStatus.SUCCESS
        assert result.is_valid
        assert not result.has_errors
        assert not result.has_warnings
        assert result.metadata == {"test": "meta"}
        assert result.request_id == "test_request"
    
    def test_create_error_result(self):
        """æµ‹è¯•åˆ›å»ºé”™è¯¯ç»“æœ"""
        error = ValidationError(
            code="TEST_ERROR",
            message="æµ‹è¯•é”™è¯¯",
            severity=ValidationSeverity.HIGH
        )
        
        result = ValidationResult.create_error(
            error=error,
            request_id="test_request"
        )
        
        assert result.status == ValidationStatus.ERROR
        assert not result.is_valid
        assert result.has_errors
        assert len(result.errors) == 1
        assert result.errors[0].code == "TEST_ERROR"
    
    def test_add_validator_result(self):
        """æµ‹è¯•æ·»åŠ éªŒè¯å™¨ç»“æœ"""
        result = ValidationResult.create_success()
        
        result.add_validator_result("test_validator", ValidationStatus.SUCCESS, 0.1)
        
        assert "test_validator" in result.validator_results
        assert result.validator_results["test_validator"] == ValidationStatus.SUCCESS
        assert "test_validator" in result.execution_order
        assert result.metrics.executed_validators == 1
    
    def test_merge_results(self):
        """æµ‹è¯•ç»“æœåˆå¹¶"""
        result1 = ValidationResult.create_success()
        result1.add_validator_result("validator1", ValidationStatus.SUCCESS, 0.1)
        
        error = ValidationError(code="ERROR1", message="é”™è¯¯1")
        result2 = ValidationResult.create_error(error)
        result2.add_validator_result("validator2", ValidationStatus.ERROR, 0.2)
        
        merged = result1.merge(result2)
        
        assert merged.status == ValidationStatus.ERROR  # å–æœ€ä¸¥é‡çš„çŠ¶æ€
        assert len(merged.errors) == 1
        assert merged.metrics.executed_validators == 2
        assert len(merged.execution_order) == 2
    
    def test_error_creation_helpers(self):
        """æµ‹è¯•é”™è¯¯åˆ›å»ºè¾…åŠ©æ–¹æ³•"""
        # XSSé”™è¯¯
        xss_error = ValidationError.create_xss_error("<script>", "security")
        assert xss_error.code == "XSS_DETECTED"
        assert xss_error.severity == ValidationSeverity.CRITICAL
        
        # SQLæ³¨å…¥é”™è¯¯
        sql_error = ValidationError.create_sql_injection_error("'; DROP TABLE", "security")
        assert sql_error.code == "SQL_INJECTION_DETECTED"
        assert sql_error.severity == ValidationSeverity.CRITICAL
        
        # å¤§å°é”™è¯¯
        size_error = ValidationError.create_size_error(2000, 1000, "content")
        assert size_error.code == "SIZE_LIMIT_EXCEEDED"
        assert size_error.severity == ValidationSeverity.HIGH
    
    def test_http_response_format(self):
        """æµ‹è¯•HTTPå“åº”æ ¼å¼"""
        # æˆåŠŸå“åº”
        success_result = ValidationResult.create_success()
        success_response = success_result.to_http_response()
        
        assert success_response["success"] is True
        assert success_response["status"] == "success"
        assert "execution_time" in success_response
        
        # é”™è¯¯å“åº”
        error = ValidationError(code="TEST_ERROR", message="æµ‹è¯•é”™è¯¯")
        error_result = ValidationResult.create_error(error, request_id="test_req")
        error_response = error_result.to_http_response()
        
        assert error_response["success"] is False
        assert error_response["status"] == "error"
        assert len(error_response["errors"]) == 1
        assert error_response["request_id"] == "test_req"


class TestValidationMetrics:
    """æµ‹è¯•éªŒè¯æŒ‡æ ‡"""
    
    def test_metrics_calculation(self):
        """æµ‹è¯•æŒ‡æ ‡è®¡ç®—"""
        metrics = ValidationMetrics()
        
        # æ·»åŠ æ‰§è¡Œè®°å½•
        metrics.add_validator_execution(0.1, True, False)  # æˆåŠŸï¼Œæœªç¼“å­˜
        metrics.add_validator_execution(0.2, False, True)  # å¤±è´¥ï¼Œç¼“å­˜
        metrics.add_validator_execution(0.1, True, True)   # æˆåŠŸï¼Œç¼“å­˜
        
        assert metrics.executed_validators == 3
        assert metrics.failed_validators == 1
        assert metrics.cache_hits == 2
        assert metrics.cache_misses == 1
        assert metrics.get_success_rate() == 2/3
        assert metrics.get_cache_hit_rate() == 2/3
        assert metrics.get_average_execution_time() == 0.4/3


class MockValidator(BaseValidator):
    """æ¨¡æ‹ŸéªŒè¯å™¨ç”¨äºæµ‹è¯•"""
    
    def __init__(self, config: Dict[str, Any], should_fail: bool = False):
        super().__init__(config)
        self.should_fail = should_fail
        self.validation_count = 0
    
    async def _do_validate(self, context: ValidationContext) -> ValidationResult:
        """æ¨¡æ‹ŸéªŒè¯é€»è¾‘"""
        self.validation_count += 1
        
        if self.should_fail:
            error = ValidationError(
                code="MOCK_ERROR",
                message="æ¨¡æ‹ŸéªŒè¯å¤±è´¥",
                validator=self.get_validator_name()
            )
            return ValidationResult.create_error(error)
        
        return ValidationResult.create_success()
    
    def get_validator_name(self) -> str:
        return "mock_validator"


class TestBaseValidator:
    """æµ‹è¯•åŸºç¡€éªŒè¯å™¨"""
    
    @pytest.mark.asyncio
    async def test_successful_validation(self):
        """æµ‹è¯•æˆåŠŸéªŒè¯"""
        validator = MockValidator({"enabled": True})
        context = ValidationContext.create_for_testing()
        
        result = await validator.validate(context)
        
        assert result.is_valid
        assert validator.validation_count == 1
        assert "mock_validator" in result.validator_results
    
    @pytest.mark.asyncio
    async def test_failed_validation(self):
        """æµ‹è¯•å¤±è´¥éªŒè¯"""
        validator = MockValidator({"enabled": True}, should_fail=True)
        context = ValidationContext.create_for_testing()
        
        result = await validator.validate(context)
        
        assert not result.is_valid
        assert len(result.errors) == 1
        assert result.errors[0].code == "MOCK_ERROR"
    
    @pytest.mark.asyncio
    async def test_skipped_validation(self):
        """æµ‹è¯•è·³è¿‡éªŒè¯"""
        validator = MockValidator({"enabled": True})
        context = ValidationContext.create_for_testing(
            skip_validators=["mock_validator"]
        )
        
        result = await validator.validate(context)
        
        assert result.status == ValidationStatus.SKIPPED
        assert validator.validation_count == 0  # åº”è¯¥æ²¡æœ‰æ‰§è¡ŒéªŒè¯é€»è¾‘
    
    @pytest.mark.asyncio
    async def test_caching(self):
        """æµ‹è¯•ç¼“å­˜åŠŸèƒ½"""
        validator = MockValidator({"enabled": True, "enable_cache": True})
        context = ValidationContext.create_for_testing(enable_cache=True)
        
        # ç¬¬ä¸€æ¬¡éªŒè¯
        result1 = await validator.validate(context)
        assert result1.is_valid
        assert validator.validation_count == 1
        
        # ç¬¬äºŒæ¬¡éªŒè¯ï¼ˆåº”è¯¥ä½¿ç”¨ç¼“å­˜ï¼‰
        result2 = await validator.validate(context)
        assert result2.is_valid
        assert validator.validation_count == 1  # éªŒè¯é€»è¾‘æ²¡æœ‰å†æ¬¡æ‰§è¡Œ
        assert result2.metrics.cache_hits > 0


class TestValidationConfig:
    """æµ‹è¯•éªŒè¯é…ç½®"""
    
    def test_config_loading(self):
        """æµ‹è¯•é…ç½®åŠ è½½"""
        config = ValidationConfig("settings.toml")
        
        assert isinstance(config.enabled, bool)
        assert isinstance(config.mode, ValidationMode)
        assert isinstance(config.max_request_size, int)
        assert isinstance(config.excluded_paths, list)
    
    def test_validator_configs(self):
        """æµ‹è¯•éªŒè¯å™¨é…ç½®"""
        config = ValidationConfig("settings.toml")
        validator_configs = config.get_validator_configs()
        
        assert isinstance(validator_configs, list)
        assert len(validator_configs) > 0
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å®‰å…¨éªŒè¯å™¨
        security_config = config.get_validator_config("security")
        assert security_config is not None
        assert security_config.type == "security"
        assert isinstance(security_config.enabled, bool)
    
    def test_endpoint_validators(self):
        """æµ‹è¯•ç«¯ç‚¹éªŒè¯å™¨é…ç½®"""
        config = ValidationConfig("settings.toml")
        
        # æµ‹è¯•å…·ä½“ç«¯ç‚¹
        validators = config.get_endpoint_validators("/api/chat/agent")
        assert isinstance(validators, list)
        assert len(validators) > 0
        
        # æµ‹è¯•é€šé…ç¬¦åŒ¹é…
        validators = config.get_endpoint_validators("/api/mcp/test")
        assert isinstance(validators, list)
    
    def test_config_validation(self):
        """æµ‹è¯•é…ç½®éªŒè¯"""
        config = ValidationConfig("settings.toml")
        warnings = config.validate_config()
        
        assert isinstance(warnings, list)
        # å¦‚æœé…ç½®æ­£ç¡®ï¼Œåº”è¯¥æ²¡æœ‰è­¦å‘Šæˆ–åªæœ‰å°‘é‡è­¦å‘Š
        print(f"é…ç½®è­¦å‘Šæ•°é‡: {len(warnings)}")
        for warning in warnings:
            print(f"  - {warning}")
    
    def test_priority_mapping(self):
        """æµ‹è¯•ä¼˜å…ˆçº§æ˜ å°„"""
        config = ValidationConfig("settings.toml")
        
        # æµ‹è¯•å·²é…ç½®çš„éªŒè¯å™¨ä¼˜å…ˆçº§
        security_priority = config.get_validator_priority("security")
        assert security_priority == ValidatorPriority.CRITICAL
        
        size_priority = config.get_validator_priority("size")
        assert size_priority == ValidatorPriority.HIGH
        
        # æµ‹è¯•æœªé…ç½®çš„éªŒè¯å™¨ï¼ˆåº”è¯¥è¿”å›é»˜è®¤ä¼˜å…ˆçº§ï¼‰
        unknown_priority = config.get_validator_priority("unknown")
        assert unknown_priority == ValidatorPriority.MEDIUM


if __name__ == "__main__":
    # è¿è¡Œç®€å•çš„æµ‹è¯•
    print("ğŸ§ª è¿è¡ŒéªŒè¯ç³»ç»Ÿé˜¶æ®µä¸€æµ‹è¯•...")
    
    # æµ‹è¯•ä¸Šä¸‹æ–‡åˆ›å»º
    print("âœ… æµ‹è¯•éªŒè¯ä¸Šä¸‹æ–‡åˆ›å»º...")
    context = ValidationContext.create_for_testing(request_data={"test": "data"})
    print(f"   ä¸Šä¸‹æ–‡æ‘˜è¦: {context.to_summary()}")
    
    # æµ‹è¯•éªŒè¯ç»“æœ
    print("âœ… æµ‹è¯•éªŒè¯ç»“æœåˆ›å»º...")
    result = ValidationResult.create_success(request_id="test_req")
    print(f"   ç»“æœæ‘˜è¦: {result.to_summary()}")
    
    # æµ‹è¯•é…ç½®åŠ è½½
    print("âœ… æµ‹è¯•é…ç½®åŠ è½½...")
    config = ValidationConfig("settings.toml")
    print(f"   éªŒè¯ç³»ç»Ÿå¯ç”¨: {config.enabled}")
    print(f"   éªŒè¯æ¨¡å¼: {config.mode.value}")
    print(f"   é…ç½®çš„éªŒè¯å™¨æ•°é‡: {len(config.get_validator_configs())}")
    
    # æµ‹è¯•é…ç½®éªŒè¯
    warnings = config.validate_config()
    if warnings:
        print(f"âš ï¸  é…ç½®è­¦å‘Š ({len(warnings)} ä¸ª):")
        for warning in warnings:
            print(f"   - {warning}")
    else:
        print("âœ… é…ç½®éªŒè¯é€šè¿‡ï¼Œæ— è­¦å‘Š")
    
    print("\nğŸ‰ é˜¶æ®µä¸€æ ¸å¿ƒç»„ä»¶æµ‹è¯•å®Œæˆï¼")
    print("âœ… æ ¸å¿ƒæ¥å£å®šä¹‰å®Œæˆ")
    print("âœ… éªŒè¯ä¸Šä¸‹æ–‡å’Œç»“æœç±»å®Œæˆ")
    print("âœ… åŸºç¡€éªŒè¯å™¨æ¨¡æ¿å®Œæˆ")
    print("âœ… éªŒè¯é…ç½®ç³»ç»Ÿå®Œæˆ")
    print("âœ… ä¸ç°æœ‰ç³»ç»Ÿé›†æˆå®Œæˆ")
    print("\nğŸ“‹ å·²å®Œæˆå¼€å‘æ­¥éª¤é˜¶æ®µä¸€çš„æ‰€æœ‰ä»»åŠ¡ï¼")
