"""
SSE GTPlanner API

æä¾›å®Œæ•´çš„æµå¼å“åº” API åŠŸèƒ½ï¼Œæ”¯æŒå®æ—¶å·¥å…·è°ƒç”¨çŠ¶æ€æ›´æ–°å’Œå‰ç«¯é›†æˆã€‚
"""

import asyncio
import json
import logging
from typing import Dict, Any, Optional, Callable, List
from datetime import datetime

from ..context_types import AgentContext, AgentResult
from ..streaming.stream_types import (
    StreamEvent, StreamEventBuilder, StreamEventType,
    ToolCallStatus, AssistantMessageChunk
)
from ..gtplanner import GTPlanner

logger = logging.getLogger(__name__)


class SSEGTPlanner:
    """
    SSE GTPlanner API ç±»
    
    æä¾›æµå¼å“åº”å¤„ç†èƒ½åŠ›ï¼Œæ”¯æŒå®æ—¶å·¥å…·è°ƒç”¨çŠ¶æ€æ›´æ–°ã€‚
    """

    def __init__(self, verbose: bool = False):
        """
        åˆå§‹åŒ– SSE GTPlanner
        
        Args:
            verbose: æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—
        """
        self.verbose = verbose
        self.gtplanner = GTPlanner(verbose=verbose)
        self.active_sessions: Dict[str, Dict[str, Any]] = {}
        
        if verbose:
            logger.info("ğŸš€ SSE GTPlanner API åˆå§‹åŒ–å®Œæˆ")

    async def process_request_stream(
        self,
        agent_context: Dict[str, Any],
        language: str = "zh",
        response_writer: Optional[Callable[[str], None]] = None,
        include_metadata: bool = False,
        buffer_events: bool = False,
        heartbeat_interval: float = 30.0
    ) -> Dict[str, Any]:
        """
        å¤„ç†è¯·æ±‚å¹¶ç”Ÿæˆæµå¼å“åº”
        
        Args:
            agent_context: Agentä¸Šä¸‹æ–‡æ•°æ®
            language: è¯­è¨€è®¾ç½®
            response_writer: å“åº”å†™å…¥å‡½æ•°
            include_metadata: æ˜¯å¦åŒ…å«å…ƒæ•°æ®
            buffer_events: æ˜¯å¦ç¼“å†²äº‹ä»¶
            heartbeat_interval: å¿ƒè·³é—´éš”ï¼ˆç§’ï¼‰
            
        Returns:
            å¤„ç†ç»“æœ
        """
        session_id = agent_context.get("session_id", "unknown")
        start_time = datetime.now()
        
        try:
            # è®°å½•æ´»è·ƒä¼šè¯
            self.active_sessions[session_id] = {
                "start_time": start_time,
                "status": "processing",
                "language": language
            }

            # å‘é€å¯¹è¯å¼€å§‹äº‹ä»¶
            user_input = self._extract_user_input(agent_context)
            await self._send_event(
                StreamEventBuilder.conversation_start(session_id, user_input),
                response_writer
            )

            # æ„å»º AgentContext å¯¹è±¡
            context = AgentContext.from_dict(agent_context)
            
            # åˆ›å»ºæµå¼å›è°ƒ
            streaming_callbacks = self._create_streaming_callbacks(
                session_id, response_writer, include_metadata
            )

            # å¤„ç†è¯·æ±‚
            result = await self.gtplanner.process_request(
                context=context,
                language=language,
                streaming_callbacks=streaming_callbacks
            )

            # å‘é€å¯¹è¯ç»“æŸäº‹ä»¶
            execution_time = (datetime.now() - start_time).total_seconds()
            await self._send_event(
                StreamEventBuilder.conversation_end(
                    session_id,
                    {
                        "success": result.success,
                        "execution_time": execution_time,
                        "new_messages_count": len(result.new_messages),
                        "metadata": result.metadata
                    },
                    result.tool_execution_results_updates
                ),
                response_writer
            )

            # æ›´æ–°ä¼šè¯çŠ¶æ€
            self.active_sessions[session_id]["status"] = "completed"
            self.active_sessions[session_id]["end_time"] = datetime.now()

            return {
                "success": result.success,
                "session_id": session_id,
                "execution_time": execution_time,
                "new_messages": [msg.to_dict() for msg in result.new_messages],
                "tool_execution_results_updates": result.tool_execution_results_updates,
                "metadata": result.metadata,
                "error": result.error
            }

        except Exception as e:
            logger.error(f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {e}", exc_info=True)
            
            # å‘é€é”™è¯¯äº‹ä»¶
            await self._send_event(
                StreamEventBuilder.error(
                    session_id,
                    str(e),
                    {"error_type": type(e).__name__}
                ),
                response_writer
            )

            # æ›´æ–°ä¼šè¯çŠ¶æ€
            self.active_sessions[session_id]["status"] = "failed"
            self.active_sessions[session_id]["error"] = str(e)
            self.active_sessions[session_id]["end_time"] = datetime.now()

            return {
                "success": False,
                "session_id": session_id,
                "error": str(e),
                "execution_time": (datetime.now() - start_time).total_seconds()
            }

        finally:
            # æ¸…ç†æ´»è·ƒä¼šè¯ï¼ˆå»¶è¿Ÿæ¸…ç†ï¼Œä¿ç•™ä¸€æ®µæ—¶é—´ç”¨äºè°ƒè¯•ï¼‰
            asyncio.create_task(self._cleanup_session(session_id, delay=300))

    def _create_streaming_callbacks(
        self,
        session_id: str,
        response_writer: Optional[Callable[[str], None]],
        include_metadata: bool
    ) -> Dict[str, Callable]:
        """åˆ›å»ºæµå¼å›è°ƒå‡½æ•°"""
        
        async def on_llm_start(data: Dict[str, Any]) -> None:
            """LLM å¼€å§‹å›è°ƒ"""
            await self._send_event(
                StreamEventBuilder.assistant_message_start(session_id),
                response_writer
            )

        async def on_llm_chunk(data: Dict[str, Any]) -> None:
            """LLM æµå¼æ•°æ®å›è°ƒ"""
            content = data.get("content", "")
            if content:
                chunk = AssistantMessageChunk(
                    content=content,
                    is_complete=False,
                    chunk_index=data.get("chunk_index", 0),
                    total_chunks=data.get("total_chunks")
                )
                await self._send_event(
                    StreamEventBuilder.assistant_message_chunk(session_id, chunk),
                    response_writer
                )

        async def on_llm_end(data: Dict[str, Any]) -> None:
            """LLM ç»“æŸå›è°ƒ"""
            complete_message = data.get("complete_message", "")
            message_metadata = data.get("metadata") if include_metadata else None
            
            await self._send_event(
                StreamEventBuilder.assistant_message_end(
                    session_id, complete_message, message_metadata
                ),
                response_writer
            )

        async def on_tool_start(data: Dict[str, Any]) -> None:
            """å·¥å…·è°ƒç”¨å¼€å§‹å›è°ƒ"""
            tool_status = ToolCallStatus(
                tool_name=data.get("tool_name", "unknown"),
                status="starting",
                call_id=data.get("call_id"),
                progress_message=data.get("progress_message"),
                arguments=data.get("arguments")
            )
            await self._send_event(
                StreamEventBuilder.tool_call_start(session_id, tool_status),
                response_writer
            )

        async def on_tool_progress(data: Dict[str, Any]) -> None:
            """å·¥å…·è°ƒç”¨è¿›åº¦å›è°ƒ"""
            tool_status = ToolCallStatus(
                tool_name=data.get("tool_name", "unknown"),
                status="running",
                call_id=data.get("call_id"),
                progress_message=data.get("progress_message"),
                arguments=data.get("arguments")
            )
            await self._send_event(
                StreamEventBuilder.tool_call_progress(session_id, tool_status),
                response_writer
            )

        async def on_tool_end(data: Dict[str, Any]) -> None:
            """å·¥å…·è°ƒç”¨ç»“æŸå›è°ƒ"""
            tool_status = ToolCallStatus(
                tool_name=data.get("tool_name", "unknown"),
                status=data.get("status", "completed"),
                call_id=data.get("call_id"),
                progress_message=data.get("progress_message"),
                arguments=data.get("arguments"),
                result=data.get("result"),
                execution_time=data.get("execution_time"),
                error_message=data.get("error_message")
            )
            await self._send_event(
                StreamEventBuilder.tool_call_end(session_id, tool_status),
                response_writer
            )

        async def on_processing_status(data: Dict[str, Any]) -> None:
            """å¤„ç†çŠ¶æ€å›è°ƒ"""
            await self._send_event(
                StreamEventBuilder.processing_status(
                    session_id,
                    data.get("status_message", ""),
                    data.get("progress_info") if include_metadata else None
                ),
                response_writer
            )

        async def on_error(data: Dict[str, Any]) -> None:
            """é”™è¯¯å›è°ƒ"""
            await self._send_event(
                StreamEventBuilder.error(
                    session_id,
                    data.get("error_message", "æœªçŸ¥é”™è¯¯"),
                    data.get("error_details") if include_metadata else None
                ),
                response_writer
            )

        return {
            "on_llm_start": on_llm_start,
            "on_llm_chunk": on_llm_chunk,
            "on_llm_end": on_llm_end,
            "on_tool_start": on_tool_start,
            "on_tool_progress": on_tool_progress,
            "on_tool_end": on_tool_end,
            "on_processing_status": on_processing_status,
            "on_error": on_error
        }

    async def _send_event(
        self,
        event: StreamEvent,
        response_writer: Optional[Callable[[str], None]]
    ) -> None:
        """å‘é€æµå¼äº‹ä»¶"""
        if response_writer:
            try:
                sse_data = event.to_sse_format()
                if asyncio.iscoroutinefunction(response_writer):
                    await response_writer(sse_data)
                else:
                    response_writer(sse_data)
            except Exception as e:
                logger.error(f"å‘é€äº‹ä»¶å¤±è´¥: {e}")

    def _extract_user_input(self, agent_context: Dict[str, Any]) -> str:
        """ä»ä¸Šä¸‹æ–‡æå–ç”¨æˆ·è¾“å…¥"""
        dialogue_history = agent_context.get("dialogue_history", [])
        if dialogue_history:
            # æŸ¥æ‰¾æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
            for message in reversed(dialogue_history):
                if message.get("role") == "user":
                    return message.get("content", "")
        return "æœªçŸ¥è¾“å…¥"

    async def _cleanup_session(self, session_id: str, delay: int = 300) -> None:
        """å»¶è¿Ÿæ¸…ç†ä¼šè¯"""
        await asyncio.sleep(delay)
        if session_id in self.active_sessions:
            del self.active_sessions[session_id]
            if self.verbose:
                logger.info(f"æ¸…ç†ä¼šè¯: {session_id}")

    def get_api_status(self) -> Dict[str, Any]:
        """è·å– API çŠ¶æ€ä¿¡æ¯"""
        active_count = len(self.active_sessions)
        
        return {
            "status": "running",
            "active_sessions": active_count,
            "sessions": list(self.active_sessions.keys()),
            "gtplanner_status": "ready" if self.gtplanner else "not_initialized",
            "verbose_mode": self.verbose,
            "timestamp": datetime.now().isoformat()
        }

    def get_session_status(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ç‰¹å®šä¼šè¯çŠ¶æ€"""
        return self.active_sessions.get(session_id)

    async def close(self) -> None:
        """å…³é—­ API"""
        if self.verbose:
            logger.info("ğŸ”„ å…³é—­ SSE GTPlanner API")
        
        # æ¸…ç†æ‰€æœ‰æ´»è·ƒä¼šè¯
        self.active_sessions.clear()
        
        if self.verbose:
            logger.info("âœ… SSE GTPlanner API å·²å…³é—­")