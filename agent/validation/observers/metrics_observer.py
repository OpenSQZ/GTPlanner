"""
æŒ‡æ ‡è§‚å¯Ÿè€…

åŸºäºè§‚å¯Ÿè€…æ¨¡å¼çš„æŒ‡æ ‡æ”¶é›†å®ç°ï¼Œæä¾›ï¼š
- éªŒè¯æˆåŠŸç‡ç»Ÿè®¡
- éªŒè¯å™¨æ‰§è¡Œæ—¶é—´ç»Ÿè®¡
- é”™è¯¯ç±»å‹åˆ†å¸ƒç»Ÿè®¡
- ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡
- æŒ‡æ ‡æ•°æ®å¯¼å‡º
"""

import time
import json
from typing import Dict, Any, Optional, List
from collections import defaultdict, Counter
from threading import Lock
from ..core.interfaces import IValidationObserver, IValidationMetrics
from ..core.validation_context import ValidationContext
from ..core.validation_result import ValidationResult, ValidationStatus


class ValidationMetricsCollector(IValidationMetrics):
    """éªŒè¯æŒ‡æ ‡æ”¶é›†å™¨ - å®ç°IValidationMetricsæ¥å£"""
    
    def __init__(self):
        self._lock = Lock()
        
        # éªŒè¯å™¨æŒ‡æ ‡
        self.validator_times: Dict[str, List[float]] = defaultdict(list)
        self.validator_results: Dict[str, Counter] = defaultdict(Counter)
        self.validator_cache_stats: Dict[str, Dict[str, int]] = defaultdict(lambda: {"hits": 0, "misses": 0})
        
        # å…¨å±€æŒ‡æ ‡
        self.total_validations = 0
        self.successful_validations = 0
        self.failed_validations = 0
        self.total_execution_time = 0.0
        
        # é”™è¯¯ç»Ÿè®¡
        self.error_codes: Counter = Counter()
        self.error_severities: Counter = Counter()
        self.error_validators: Counter = Counter()
        
        # ç«¯ç‚¹ç»Ÿè®¡
        self.endpoint_stats: Dict[str, Dict[str, Any]] = defaultdict(lambda: {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_time": 0.0,
            "avg_time": 0.0
        })
        
        # æ—¶é—´ç»Ÿè®¡
        self.start_time = time.time()
        self.last_reset_time = time.time()
    
    def record_validation_time(self, validator_name: str, duration: float) -> None:
        """è®°å½•éªŒè¯æ‰§è¡Œæ—¶é—´
        
        Args:
            validator_name: éªŒè¯å™¨åç§°
            duration: æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
        """
        with self._lock:
            self.validator_times[validator_name].append(duration)
            
            # é™åˆ¶å†å²è®°å½•æ•°é‡ï¼ˆä¿ç•™æœ€è¿‘1000æ¬¡ï¼‰
            if len(self.validator_times[validator_name]) > 1000:
                self.validator_times[validator_name] = self.validator_times[validator_name][-1000:]
    
    def record_validation_result(self, validator_name: str, success: bool) -> None:
        """è®°å½•éªŒè¯ç»“æœ
        
        Args:
            validator_name: éªŒè¯å™¨åç§°
            success: éªŒè¯æ˜¯å¦æˆåŠŸ
        """
        with self._lock:
            status = "success" if success else "failure"
            self.validator_results[validator_name][status] += 1
    
    def record_cache_hit(self, validator_name: str, hit: bool) -> None:
        """è®°å½•ç¼“å­˜å‘½ä¸­æƒ…å†µ
        
        Args:
            validator_name: éªŒè¯å™¨åç§°
            hit: æ˜¯å¦å‘½ä¸­ç¼“å­˜
        """
        with self._lock:
            if hit:
                self.validator_cache_stats[validator_name]["hits"] += 1
            else:
                self.validator_cache_stats[validator_name]["misses"] += 1
    
    def get_metrics(self) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡æ•°æ®
        
        Returns:
            æŒ‡æ ‡æ•°æ®å­—å…¸
        """
        with self._lock:
            current_time = time.time()
            uptime = current_time - self.start_time
            
            # è®¡ç®—éªŒè¯å™¨å¹³å‡æ—¶é—´
            validator_avg_times = {}
            for validator_name, times in self.validator_times.items():
                if times:
                    validator_avg_times[validator_name] = sum(times) / len(times)
            
            # è®¡ç®—éªŒè¯å™¨æˆåŠŸç‡
            validator_success_rates = {}
            for validator_name, results in self.validator_results.items():
                total = results["success"] + results["failure"]
                if total > 0:
                    validator_success_rates[validator_name] = results["success"] / total
            
            # è®¡ç®—ç¼“å­˜å‘½ä¸­ç‡
            validator_cache_rates = {}
            for validator_name, stats in self.validator_cache_stats.items():
                total = stats["hits"] + stats["misses"]
                if total > 0:
                    validator_cache_rates[validator_name] = stats["hits"] / total
            
            return {
                # å…¨å±€æŒ‡æ ‡
                "uptime_seconds": uptime,
                "total_validations": self.total_validations,
                "successful_validations": self.successful_validations,
                "failed_validations": self.failed_validations,
                "overall_success_rate": self.successful_validations / self.total_validations if self.total_validations > 0 else 0,
                "total_execution_time": self.total_execution_time,
                "average_execution_time": self.total_execution_time / self.total_validations if self.total_validations > 0 else 0,
                
                # éªŒè¯å™¨æŒ‡æ ‡
                "validator_avg_times": validator_avg_times,
                "validator_success_rates": validator_success_rates,
                "validator_cache_rates": validator_cache_rates,
                "validator_execution_counts": {
                    name: len(times) for name, times in self.validator_times.items()
                },
                
                # é”™è¯¯ç»Ÿè®¡
                "error_codes": dict(self.error_codes.most_common(10)),
                "error_severities": dict(self.error_severities),
                "error_validators": dict(self.error_validators.most_common(10)),
                
                # ç«¯ç‚¹ç»Ÿè®¡
                "endpoint_stats": dict(self.endpoint_stats),
                
                # æ—¶é—´ä¿¡æ¯
                "collection_start_time": self.start_time,
                "last_reset_time": self.last_reset_time,
                "metrics_collected_at": current_time
            }
    
    def reset_metrics(self) -> None:
        """é‡ç½®æ‰€æœ‰æŒ‡æ ‡æ•°æ®"""
        with self._lock:
            self.validator_times.clear()
            self.validator_results.clear()
            self.validator_cache_stats.clear()
            
            self.total_validations = 0
            self.successful_validations = 0
            self.failed_validations = 0
            self.total_execution_time = 0.0
            
            self.error_codes.clear()
            self.error_severities.clear()
            self.error_validators.clear()
            
            self.endpoint_stats.clear()
            
            self.last_reset_time = time.time()
    
    def record_endpoint_validation(self, endpoint: str, success: bool, execution_time: float) -> None:
        """è®°å½•ç«¯ç‚¹éªŒè¯ç»Ÿè®¡
        
        Args:
            endpoint: ç«¯ç‚¹è·¯å¾„
            success: éªŒè¯æ˜¯å¦æˆåŠŸ
            execution_time: æ‰§è¡Œæ—¶é—´
        """
        with self._lock:
            stats = self.endpoint_stats[endpoint]
            stats["total_requests"] += 1
            stats["total_time"] += execution_time
            
            if success:
                stats["successful_requests"] += 1
            else:
                stats["failed_requests"] += 1
            
            # æ›´æ–°å¹³å‡æ—¶é—´
            stats["avg_time"] = stats["total_time"] / stats["total_requests"]


class MetricsObserver(IValidationObserver):
    """æŒ‡æ ‡è§‚å¯Ÿè€… - æ”¶é›†éªŒè¯è¿‡ç¨‹çš„æ€§èƒ½å’Œç»Ÿè®¡æŒ‡æ ‡
    
    æä¾›ä¼ä¸šçº§çš„æŒ‡æ ‡æ”¶é›†åŠŸèƒ½ï¼š
    - å®æ—¶æ€§èƒ½æŒ‡æ ‡æ”¶é›†
    - éªŒè¯å™¨æˆåŠŸç‡ç»Ÿè®¡
    - é”™è¯¯ç±»å‹åˆ†å¸ƒåˆ†æ
    - ç¼“å­˜å‘½ä¸­ç‡ç›‘æ§
    - æŒ‡æ ‡æ•°æ®å¯¼å‡ºå’Œå¯è§†åŒ–
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        
        # æŒ‡æ ‡é…ç½®
        self.enabled = self.config.get("enabled", True)
        self.include_timing = self.config.get("include_timing", True)
        self.include_success_rate = self.config.get("include_success_rate", True)
        self.include_error_details = self.config.get("include_error_details", True)
        self.export_interval = self.config.get("export_interval", 60)
        self.max_history_size = self.config.get("max_history_size", 1000)
        
        # åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨
        self.metrics_collector = ValidationMetricsCollector()
        
        # æœ€åå¯¼å‡ºæ—¶é—´
        self.last_export_time = time.time()
    
    async def on_validation_start(self, context: ValidationContext) -> None:
        """éªŒè¯å¼€å§‹äº‹ä»¶
        
        Args:
            context: éªŒè¯ä¸Šä¸‹æ–‡
        """
        if not self.enabled:
            return
        
        # è®°å½•éªŒè¯å¼€å§‹æ—¶é—´ï¼ˆå­˜å‚¨åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼‰
        context.add_metadata("metrics_start_time", time.time())
    
    async def on_validation_step(self, validator_name: str, result: ValidationResult) -> None:
        """éªŒè¯æ­¥éª¤å®Œæˆäº‹ä»¶
        
        Args:
            validator_name: éªŒè¯å™¨åç§°
            result: éªŒè¯ç»“æœ
        """
        if not self.enabled:
            return
        
        # è®°å½•éªŒè¯å™¨æ‰§è¡Œæ—¶é—´
        if self.include_timing:
            self.metrics_collector.record_validation_time(validator_name, result.execution_time)
        
        # è®°å½•éªŒè¯å™¨ç»“æœ
        if self.include_success_rate:
            success = result.status in [ValidationStatus.SUCCESS, ValidationStatus.WARNING]
            self.metrics_collector.record_validation_result(validator_name, success)
        
        # è®°å½•ç¼“å­˜ç»Ÿè®¡
        cache_hits = result.metrics.cache_hits
        cache_misses = result.metrics.cache_misses
        
        if cache_hits > 0:
            self.metrics_collector.record_cache_hit(validator_name, True)
        if cache_misses > 0:
            self.metrics_collector.record_cache_hit(validator_name, False)
    
    async def on_validation_complete(self, result: ValidationResult) -> None:
        """éªŒè¯å®Œæˆäº‹ä»¶
        
        Args:
            result: æœ€ç»ˆéªŒè¯ç»“æœ
        """
        if not self.enabled:
            return
        
        # æ›´æ–°å…¨å±€ç»Ÿè®¡
        self.metrics_collector.total_validations += 1
        self.metrics_collector.total_execution_time += result.execution_time
        
        if result.is_valid:
            self.metrics_collector.successful_validations += 1
        else:
            self.metrics_collector.failed_validations += 1
        
        # è®°å½•é”™è¯¯ç»Ÿè®¡
        if self.include_error_details and result.has_errors:
            for error in result.errors:
                self.metrics_collector.error_codes[error.code] += 1
                self.metrics_collector.error_severities[error.severity.name] += 1
                if error.validator:
                    self.metrics_collector.error_validators[error.validator] += 1
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¯¼å‡ºæŒ‡æ ‡
        current_time = time.time()
        if current_time - self.last_export_time >= self.export_interval:
            await self._export_metrics()
            self.last_export_time = current_time
    
    async def on_validation_error(self, error: Exception, context: Optional[ValidationContext] = None) -> None:
        """éªŒè¯é”™è¯¯äº‹ä»¶
        
        Args:
            error: å‘ç”Ÿçš„å¼‚å¸¸
            context: éªŒè¯ä¸Šä¸‹æ–‡ï¼ˆå¯èƒ½ä¸ºNoneï¼‰
        """
        if not self.enabled:
            return
        
        # è®°å½•ç³»ç»Ÿé”™è¯¯
        self.metrics_collector.error_codes[f"SYSTEM_ERROR_{type(error).__name__}"] += 1
        self.metrics_collector.error_severities["CRITICAL"] += 1
        
        # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œè®°å½•ç«¯ç‚¹é”™è¯¯
        if context:
            endpoint = context.request_path
            self.metrics_collector.record_endpoint_validation(endpoint, False, context.get_execution_time())
    
    async def _export_metrics(self) -> None:
        """å¯¼å‡ºæŒ‡æ ‡æ•°æ®"""
        try:
            metrics_data = self.metrics_collector.get_metrics()
            
            # è¿™é‡Œå¯ä»¥å®ç°æŒ‡æ ‡æ•°æ®çš„å¯¼å‡ºé€»è¾‘
            # ä¾‹å¦‚ï¼šå†™å…¥æ–‡ä»¶ã€å‘é€åˆ°ç›‘æ§ç³»ç»Ÿã€æ›´æ–°æ•°æ®åº“ç­‰
            
            # ç®€å•çš„æ§åˆ¶å°è¾“å‡ºï¼ˆå¯ä»¥æ›¿æ¢ä¸ºå®é™…çš„å¯¼å‡ºé€»è¾‘ï¼‰
            print(f"ğŸ“Š éªŒè¯æŒ‡æ ‡å¯¼å‡º - æ€»éªŒè¯æ¬¡æ•°: {metrics_data['total_validations']}, "
                  f"æˆåŠŸç‡: {metrics_data['overall_success_rate']:.1%}, "
                  f"å¹³å‡æ‰§è¡Œæ—¶é—´: {metrics_data['average_execution_time']:.3f}s")
            
        except Exception as e:
            print(f"Warning: Failed to export metrics: {e}")
    
    def get_observer_name(self) -> str:
        """è·å–è§‚å¯Ÿè€…åç§°
        
        Returns:
            è§‚å¯Ÿè€…åç§°
        """
        return "metrics_observer"
    
    def get_current_metrics(self) -> Dict[str, Any]:
        """è·å–å½“å‰æŒ‡æ ‡æ•°æ®
        
        Returns:
            å½“å‰æŒ‡æ ‡æ•°æ®å­—å…¸
        """
        return self.metrics_collector.get_metrics()
    
    def get_metrics_summary(self) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡æ‘˜è¦
        
        Returns:
            æŒ‡æ ‡æ‘˜è¦å­—å…¸
        """
        metrics = self.metrics_collector.get_metrics()
        
        return {
            "total_validations": metrics["total_validations"],
            "success_rate": metrics["overall_success_rate"],
            "avg_execution_time": metrics["average_execution_time"],
            "top_error_codes": list(metrics["error_codes"].keys())[:5],
            "active_validators": len(metrics["validator_avg_times"]),
            "uptime_hours": metrics["uptime_seconds"] / 3600
        }
    
    def export_metrics_to_json(self) -> str:
        """å¯¼å‡ºæŒ‡æ ‡ä¸ºJSONæ ¼å¼
        
        Returns:
            JSONæ ¼å¼çš„æŒ‡æ ‡æ•°æ®
        """
        metrics = self.metrics_collector.get_metrics()
        return json.dumps(metrics, indent=2, ensure_ascii=False)
    
    def export_metrics_to_csv(self) -> str:
        """å¯¼å‡ºæŒ‡æ ‡ä¸ºCSVæ ¼å¼
        
        Returns:
            CSVæ ¼å¼çš„æŒ‡æ ‡æ•°æ®
        """
        metrics = self.metrics_collector.get_metrics()
        lines = []
        
        # éªŒè¯å™¨æ€§èƒ½æ•°æ®
        lines.append("validator_name,avg_time,success_rate,cache_hit_rate,execution_count")
        
        for validator_name in metrics["validator_avg_times"]:
            avg_time = metrics["validator_avg_times"].get(validator_name, 0)
            success_rate = metrics["validator_success_rates"].get(validator_name, 0)
            cache_rate = metrics["validator_cache_rates"].get(validator_name, 0)
            exec_count = metrics["validator_execution_counts"].get(validator_name, 0)
            
            lines.append(f"{validator_name},{avg_time:.3f},{success_rate:.3f},{cache_rate:.3f},{exec_count}")
        
        return "\n".join(lines)
    
    async def record_success(self, context: ValidationContext, execution_time: float) -> None:
        """è®°å½•æˆåŠŸäº‹ä»¶
        
        Args:
            context: éªŒè¯ä¸Šä¸‹æ–‡
            execution_time: æ‰§è¡Œæ—¶é—´
        """
        if self.enabled:
            endpoint = context.request_path
            self.metrics_collector.record_endpoint_validation(endpoint, True, execution_time)
    
    async def record_error(self, path: str, error: str, execution_time: float) -> None:
        """è®°å½•é”™è¯¯äº‹ä»¶
        
        Args:
            path: è¯·æ±‚è·¯å¾„
            error: é”™è¯¯ä¿¡æ¯
            execution_time: æ‰§è¡Œæ—¶é—´
        """
        if self.enabled:
            self.metrics_collector.record_endpoint_validation(path, False, execution_time)
    
    def reset_metrics(self) -> None:
        """é‡ç½®æŒ‡æ ‡æ•°æ®"""
        self.metrics_collector.reset_metrics()
    
    def get_validator_performance(self, validator_name: str) -> Optional[Dict[str, Any]]:
        """è·å–ç‰¹å®šéªŒè¯å™¨çš„æ€§èƒ½æŒ‡æ ‡
        
        Args:
            validator_name: éªŒè¯å™¨åç§°
            
        Returns:
            éªŒè¯å™¨æ€§èƒ½æŒ‡æ ‡ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        metrics = self.metrics_collector.get_metrics()
        
        if validator_name not in metrics["validator_avg_times"]:
            return None
        
        return {
            "name": validator_name,
            "avg_execution_time": metrics["validator_avg_times"][validator_name],
            "success_rate": metrics["validator_success_rates"].get(validator_name, 0),
            "cache_hit_rate": metrics["validator_cache_rates"].get(validator_name, 0),
            "execution_count": metrics["validator_execution_counts"].get(validator_name, 0),
            "total_time": sum(self.metrics_collector.validator_times.get(validator_name, [])),
            "recent_times": self.metrics_collector.validator_times.get(validator_name, [])[-10:]  # æœ€è¿‘10æ¬¡
        }
    
    def get_top_error_codes(self, limit: int = 10) -> List[tuple[str, int]]:
        """è·å–æœ€å¸¸è§çš„é”™è¯¯ä»£ç 
        
        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            é”™è¯¯ä»£ç å’Œæ¬¡æ•°çš„å…ƒç»„åˆ—è¡¨
        """
        return self.metrics_collector.error_codes.most_common(limit)
    
    def get_endpoint_performance(self) -> Dict[str, Dict[str, Any]]:
        """è·å–ç«¯ç‚¹æ€§èƒ½ç»Ÿè®¡
        
        Returns:
            ç«¯ç‚¹æ€§èƒ½ç»Ÿè®¡å­—å…¸
        """
        return dict(self.metrics_collector.endpoint_stats)
