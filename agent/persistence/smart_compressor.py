"""
æ™ºèƒ½ä¸Šä¸‹æ–‡å‹ç¼©ç³»ç»Ÿ

ç®€å•ã€é«˜æ•ˆçš„å‹ç¼©ç³»ç»Ÿï¼š
1. åŸºäºtokenå’Œæ¶ˆæ¯æ•°é‡çš„å³æ—¶é˜ˆå€¼åˆ¤æ–­
2. æ¯æ¬¡å¯¹è¯åè‡ªåŠ¨æ£€æŸ¥å¹¶å¼‚æ­¥å‹ç¼©
3. ä¸é˜»å¡å¯¹è¯æµç¨‹ï¼Œç”¨æˆ·æ— æ„ŸçŸ¥
4. æ”¯æŒå¤šç§æ•°æ®æºï¼ˆSQLiteã€Redisã€MongoDBç­‰ï¼‰
"""

import asyncio
import json
import time
import uuid
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
from enum import Enum

from utils.openai_client import OpenAIClient
from .data_source_interface import DataSourceInterface, SQLiteDataSourceAdapter


class CompressionLevel(Enum):
    """å‹ç¼©çº§åˆ«"""
    LIGHT = "light"      # ä¿ç•™80%ä¿¡æ¯
    MEDIUM = "medium"    # ä¿ç•™60%ä¿¡æ¯
    HEAVY = "heavy"      # ä¿ç•™40%ä¿¡æ¯


@dataclass
class CompressionConfig:
    """å‹ç¼©é…ç½®"""
    # è§¦å‘é˜ˆå€¼
    max_tokens: int = 8000           # æœ€å¤§tokenæ•°
    max_messages: int = 50           # æœ€å¤§æ¶ˆæ¯æ•°
    preserve_recent_count: int = 5   # ä¿ç•™æœ€è¿‘æ¶ˆæ¯æ•°
    
    # å‹ç¼©è®¾ç½®
    enable_compression: bool = True  # å¯ç”¨å‹ç¼©
    default_level: CompressionLevel = CompressionLevel.MEDIUM

    # é‡è¯•
    MAX_RETRIES = 3  # å®šä¹‰æœ€å¤§é‡è¯•æ¬¡æ•°
    RETRY_DELAY = 5  # é‡è¯•å‰çš„ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰


class SmartCompressor:
    """æ™ºèƒ½å‹ç¼©å™¨"""
    
    def __init__(self, data_source: DataSourceInterface, config: Optional[CompressionConfig] = None):
        """
        åˆå§‹åŒ–æ™ºèƒ½å‹ç¼©å™¨
        
        Args:
            data_source: æ•°æ®æºæ¥å£å®ç°
            config: å‹ç¼©é…ç½®
        """
        self.data_source = data_source
        self.config = config or CompressionConfig()
        self.openai_client = OpenAIClient()
        
        # å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—
        self.compression_queue = asyncio.Queue()
        self.worker_task: Optional[asyncio.Task] = None
        self.is_running = False
    
    async def start(self):
        """å¯åŠ¨å‹ç¼©æœåŠ¡"""
        if self.is_running:
            return
        
        self.is_running = True
        self.worker_task = asyncio.create_task(self._compression_worker())
        print("ğŸ—œï¸ æ™ºèƒ½å‹ç¼©æœåŠ¡å·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢å‹ç¼©æœåŠ¡"""
        if not self.is_running:
            return
        
        self.is_running = False
        
        if self.worker_task:
            self.worker_task.cancel()
            try:
                await self.worker_task
            except asyncio.CancelledError:
                pass
        
        print("ğŸ—œï¸ æ™ºèƒ½å‹ç¼©æœåŠ¡å·²åœæ­¢")
    
    async def should_compress(self, session_id: str) -> bool:
        """
        æ£€æŸ¥ä¼šè¯æ˜¯å¦éœ€è¦å‹ç¼©ï¼ˆå¼‚æ­¥æ–¹æ³•ï¼Œå¿«é€Ÿåˆ¤æ–­ï¼‰
        
        Args:
            session_id: ä¼šè¯ID
            
        Returns:
            æ˜¯å¦éœ€è¦å‹ç¼©
        """
        if not self.config.enable_compression:
            return False
        
        try:
            # ä»æ•°æ®æºè·å–tokenç»Ÿè®¡ä¿¡æ¯
            compressed_context = await self.data_source.get_active_compressed_context(session_id)

            if not compressed_context:
                # è¿™æ˜¯å¼‚å¸¸æƒ…å†µï¼Œè¯´æ˜æ•°æ®ä¸ä¸€è‡´
                print(f"âš ï¸ è­¦å‘Šï¼šä¼šè¯ {session_id} ç¼ºå°‘å‹ç¼©ä¸Šä¸‹æ–‡è®°å½•ï¼Œæ— æ³•æ£€æµ‹å‹ç¼©éœ€æ±‚")
                return False

            # ä»å‹ç¼©ä¸Šä¸‹æ–‡è·å–ç»Ÿè®¡ä¿¡æ¯
            message_count = compressed_context["compressed_message_count"]
            token_count = compressed_context["compressed_token_count"]

            # è¶…è¿‡ä»»ä¸€é˜ˆå€¼å°±å‹ç¼©
            return (token_count > self.config.max_tokens or
                   message_count > self.config.max_messages)
            
        except Exception as e:
            print(f"âš ï¸ å‹ç¼©æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    async def compress_if_needed(self, session_id: str):
        """
        å¦‚æœéœ€è¦åˆ™å¼‚æ­¥å‹ç¼©ï¼ˆä¸é˜»å¡è°ƒç”¨æ–¹ï¼‰
        
        Args:
            session_id: ä¼šè¯ID
        """
        if await self.should_compress(session_id):
            # å¼‚æ­¥è°ƒåº¦å‹ç¼©ä»»åŠ¡
            await self._schedule_compression(session_id)
    
    async def _schedule_compression(self, session_id: str):
        """è°ƒåº¦å‹ç¼©ä»»åŠ¡"""
        try:
            task = {
                'session_id': session_id,
                'scheduled_at': datetime.now(),
                'retries': 0,
            }
            
            await self.compression_queue.put(task)
            print(f"ğŸ“‹ å·²è°ƒåº¦å‹ç¼©ä»»åŠ¡: {session_id}")
            
        except Exception as e:
            print(f"âš ï¸ è°ƒåº¦å‹ç¼©å¤±è´¥: {e}")
    
    async def _compression_worker(self):
        """å‹ç¼©å·¥ä½œçº¿ç¨‹"""
        while self.is_running:
            try:
                # ç­‰å¾…å‹ç¼©ä»»åŠ¡
                task = await asyncio.wait_for(
                    self.compression_queue.get(),
                    timeout=1.0
                )

                # æ‰§è¡Œå‹ç¼©
                await self._execute_compression(task)

                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                self.compression_queue.task_done()

            except asyncio.TimeoutError:
                continue
            except Exception as e:
                print(f"ä»»åŠ¡ {task} æ‰§è¡Œå¤±è´¥: {e}")
                if task and task.get("retries", 0) < self.config.MAX_RETRIES:
                    task["retries"] += 1
                    print(
                        f"ä»»åŠ¡ {task} å‡†å¤‡é‡è¯• "
                        f"(ç¬¬ {task.get('retries')} æ¬¡)ã€‚"
                        f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡æ–°å…¥é˜Ÿã€‚"
                    )
                    
                    # ç­‰å¾…ä¸€æ®µæ—¶é—´
                    await asyncio.sleep(self.config.RETRY_DELAY) 
                    
                    # é‡æ–°å°†å°è£…åçš„ä»»åŠ¡æ”¾å›é˜Ÿåˆ—
                    await self.compression_queue.put(task) 
                else:
                    # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°æˆ– task_wrapper æ— æ•ˆï¼Œæ”¾å¼ƒä»»åŠ¡
                    if task:
                        print(
                            f"ä»»åŠ¡ {task} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° "
                            f"({self.config.MAX_RETRIES})ï¼Œä»»åŠ¡å¤±è´¥å¹¶æ”¾å¼ƒã€‚"
                        )
                    # æ ‡è®°ä»»åŠ¡å®Œæˆ (å¤±è´¥æ”¾å¼ƒæ—¶)
                    ## TODO å¢åŠ å‘Šè­¦æœºåˆ¶ï¼Œéœ€è¦æ„ŸçŸ¥åˆ°è¿™ä¸ªé—®é¢˜
                    self.compression_queue.task_done()
    
    async def _execute_compression(self, task: Dict[str, Any]):
        """æ‰§è¡Œå‹ç¼©"""
        session_id = task['session_id']
        start_time = time.time()

        # åŠ è½½ç›®æ ‡ä¼šè¯
        if not await self.data_source.load_session(session_id):
            raise Exception(f"æ— æ³•åŠ è½½ä¼šè¯è¿›è¡Œå‹ç¼©: {session_id}")

        # è·å–æ¶ˆæ¯
        messages = await self.data_source.get_messages(session_id)

        if len(messages) <= self.config.preserve_recent_count:
            print(f"âš ï¸ æ¶ˆæ¯æ•°é‡ä¸è¶³ï¼Œè·³è¿‡å‹ç¼©: {session_id}")
            return

        # æ‰§è¡Œå‹ç¼©
        compressed_data = await self._compress_messages(messages)

        # ä¿å­˜å‹ç¼©ç»“æœ
        await self._save_compression_result(session_id, compressed_data)

        execution_time = time.time() - start_time

        print(f"âœ… å‹ç¼©å®Œæˆ: {session_id}")
        print(f"   åŸå§‹æ¶ˆæ¯: {len(messages)}, å‹ç¼©å: {len(compressed_data.get('messages', []))}")
        print(f"   è€—æ—¶: {execution_time:.1f}s")
    
    def _estimate_tokens(self, messages: List[Dict[str, Any]]) -> int:
        """ä¼°ç®—tokenæ•°é‡"""
        total = 0
        for msg in messages:
            content = msg.get('content', '')
            # ç®€å•ä¼°ç®—ï¼šä¸­æ–‡1å­—ç¬¦â‰ˆ1tokenï¼Œè‹±æ–‡1è¯â‰ˆ1token
            chinese_chars = len([c for c in content if '\u4e00' <= c <= '\u9fff'])
            english_words = len(content.replace('ï¼Œ', ' ').replace('ã€‚', ' ').split())
            total += chinese_chars + english_words
        return total
    
    async def _compress_messages(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """å‹ç¼©æ¶ˆæ¯ - ç”Ÿæˆç»“æ„åŒ–çš„å‹ç¼©æ¶ˆæ¯åˆ—è¡¨"""
        # ä¿ç•™æœ€è¿‘çš„æ¶ˆæ¯
        recent_messages = messages[-self.config.preserve_recent_count:]

        # éœ€è¦å‹ç¼©çš„æ¶ˆæ¯
        messages_to_compress = messages[:-self.config.preserve_recent_count]

        if not messages_to_compress:
            return {
                'messages': messages,
                'summary': 'æ— éœ€å‹ç¼©',
                'key_decisions': [],
                'compression_method': 'no_compression'
            }

        # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å‹ç¼©ï¼Œç”Ÿæˆç»“æ„åŒ–ç»“æœ
        compression_result = await self._llm_intelligent_compress(messages_to_compress)

        # æ„å»ºæœ€ç»ˆçš„å‹ç¼©æ¶ˆæ¯åˆ—è¡¨
        compressed_messages = []

        # æ·»åŠ å‹ç¼©åçš„ç»“æ„åŒ–æ¶ˆæ¯
        compressed_messages.extend(compression_result.get('compressed_messages', []))

        # æ·»åŠ æœ€è¿‘çš„å®Œæ•´æ¶ˆæ¯
        compressed_messages.extend(recent_messages)

        return {
            'messages': compressed_messages,
            'summary': compression_result.get('summary', ''),
            'key_decisions': compression_result.get('key_decisions', []),
            'compression_method': 'llm_intelligent',
            'original_count': len(messages),
            'compressed_count': len(compressed_messages)
        }
    
    async def _llm_intelligent_compress(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å‹ç¼©ï¼Œç”Ÿæˆç»“æ„åŒ–ç»“æœ"""
        # æ ¼å¼åŒ–æ¶ˆæ¯
        formatted = self._format_messages(messages)

        system_prompt = """ä½ æ˜¯ä¸“ä¸šçš„å¯¹è¯å‹ç¼©åŠ©æ‰‹ï¼Œæ“…é•¿å°†å†—é•¿çš„å¯¹è¯å‹ç¼©ä¸ºç»“æ„åŒ–çš„ç²¾ç®€ç‰ˆæœ¬ã€‚

å‹ç¼©è¦æ±‚ï¼š
1. å°†ç›¸ä¼¼çš„å¯¹è¯è½®æ¬¡åˆå¹¶ä¸ºæ›´ç®€æ´çš„æ¶ˆæ¯
2. ä¿ç•™æ‰€æœ‰é‡è¦å†³ç­–å’Œç»“è®º
3. ä¿ç•™å…³é”®çš„ç”¨æˆ·éœ€æ±‚å’Œç³»ç»Ÿå›å¤
4. ç»´æŠ¤å¯¹è¯çš„é€»è¾‘æµç¨‹å’Œä¸Šä¸‹æ–‡å…³ç³»

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
{
    "compressed_messages": [
        {
            "message_id": "compressed_1",
            "role": "user",
            "content": "åˆå¹¶åçš„ç”¨æˆ·éœ€æ±‚æˆ–é—®é¢˜",
            "metadata": {"compression_note": "åˆå¹¶äº†3æ¡ç›¸ä¼¼çš„ç”¨æˆ·æ¶ˆæ¯"}
        },
        {
            "message_id": "compressed_2",
            "role": "assistant",
            "content": "åˆå¹¶åçš„åŠ©æ‰‹å›å¤å’Œåˆ†æ",
            "metadata": {"compression_note": "åˆå¹¶äº†åŠ©æ‰‹çš„åˆ†æå’Œå»ºè®®"}
        }
    ],
    "summary": "æ•´ä½“å¯¹è¯æ‘˜è¦ï¼ŒåŒ…å«ä¸»è¦è®¨è®ºå†…å®¹å’Œç»“è®º",
    "key_decisions": ["é‡è¦å†³ç­–1", "é‡è¦å†³ç­–2"]
}"""

        prompt = f"è¯·å¯¹ä»¥ä¸‹å¯¹è¯å†å²è¿›è¡Œæ™ºèƒ½å‹ç¼©ï¼š\n\n{formatted}"

        response = await self.openai_client.chat_completion(
            messages=[{"role": "user", "content": prompt}],
            system_prompt=system_prompt,
            temperature=0.1,
            max_tokens=2000
        )

        # è§£æJSONç»“æœ
        result_text = response.choices[0].message.content.strip()
        result = json.loads(result_text)

        # éªŒè¯å’Œè¡¥å……ç»“æœ
        compressed_messages = result.get('compressed_messages', [])
        for i, msg in enumerate(compressed_messages):
            # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨ï¼Œç”±ä»£ç ç”Ÿæˆ
            if 'message_id' not in msg:
                msg['message_id'] = f"compressed_{int(time.time())}_{i}"

            # ç”±ä»£ç è‡ªåŠ¨æ·»åŠ çš„å­—æ®µ
            msg['timestamp'] = datetime.now().isoformat()
            msg['token_count'] = len(msg.get('content', '')) // 2

            # ç¡®ä¿metadataå­˜åœ¨
            if 'metadata' not in msg:
                msg['metadata'] = {}

        return {
            'compressed_messages': compressed_messages,
            'summary': result.get('summary', ''),
            'key_decisions': result.get('key_decisions', [])
        }


    
    def _format_messages(self, messages: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–æ¶ˆæ¯ç”¨äºLLMå¤„ç†"""
        formatted = []
        for i, msg in enumerate(messages, 1):
            role = msg['role']
            content = msg['content']
            formatted.append(f"[{i}] {role}: {content}")

        return "\n".join(formatted)
    
    async def _save_compression_result(self, session_id: str, compressed_data: Dict[str, Any]):
        """ä¿å­˜å‹ç¼©ç»“æœ"""
        # è·å–ç°æœ‰å‹ç¼©ç‰ˆæœ¬
        existing = await self.data_source.get_compressed_contexts(session_id)
        next_version = len(existing) + 1

        # è®¡ç®—å‹ç¼©æ¯”
        original_count = compressed_data.get('original_count', 0)
        compressed_count = compressed_data.get('compressed_count', 0)
        compression_ratio = compressed_count / original_count if original_count > 0 else 0

        # ä¿å­˜åˆ°æ•°æ®æº
        await self.data_source.save_compressed_context(
            session_id=session_id,
            compressed_data=compressed_data,
            version=next_version,
            compression_ratio=compression_ratio,
            metadata={
                'compression_id': str(uuid.uuid4()),
                'level': self.config.default_level.value,
                'algorithm': 'smart_llm_v2',
                'created_at': datetime.now().isoformat()
            }
        )

        print(f"ğŸ’¾ å‹ç¼©ç»“æœå·²ä¿å­˜: {session_id} v{next_version}")


# å…¨å±€å‹ç¼©å™¨å®ä¾‹
_compressor: Optional[SmartCompressor] = None


def get_compressor(data_source: DataSourceInterface, config: Optional[CompressionConfig] = None) -> SmartCompressor:
    """è·å–å…¨å±€å‹ç¼©å™¨å®ä¾‹"""
    global _compressor
    if _compressor is None:
        _compressor = SmartCompressor(data_source, config)
    return _compressor


def create_sqlite_compressor(session_manager, config: Optional[CompressionConfig] = None) -> SmartCompressor:
    """
    åˆ›å»ºSQLiteå‹ç¼©å™¨çš„ä¾¿æ·æ–¹æ³•
    
    Args:
        session_manager: SQLiteSessionManagerå®ä¾‹
        config: å‹ç¼©é…ç½®
        
    Returns:
        SmartCompressorå®ä¾‹
    """
    data_source = SQLiteDataSourceAdapter(session_manager)
    return SmartCompressor(data_source, config)
