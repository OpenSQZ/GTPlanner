"""
é¢„åˆ¶ä»¶ç´¢å¼•æ„å»ºæ¨¡å—

è´Ÿè´£å°† community-prefabs.json ä¸­çš„é¢„åˆ¶ä»¶è½¬æ¢ä¸ºå‘é‡ç´¢å¼•ï¼Œä½¿ç”¨æ™ºè°±AIçš„åµŒå…¥APIå’Œæœ¬åœ°å‘é‡å­˜å‚¨ã€‚
è¿™ä¸æ˜¯ä¸€ä¸ª pocketflow nodeï¼Œè€Œæ˜¯ç‹¬ç«‹çš„å·¥å…·å‡½æ•°ã€‚
"""

import os
import json
import time
import requests
import pickle
import hashlib
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path


class LocalVectorStore:
    """æœ¬åœ°å‘é‡å­˜å‚¨"""

    def __init__(self, storage_dir: str = None):
        """
        åˆå§‹åŒ–æœ¬åœ°å‘é‡å­˜å‚¨

        Args:
            storage_dir: å­˜å‚¨ç›®å½•è·¯å¾„
        """
        if storage_dir is None:
            current_dir = Path(__file__).parent.parent.parent
            storage_dir = current_dir / "data" / "vector_store"

        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(parents=True, exist_ok=True)

        # å­˜å‚¨æ–‡ä»¶è·¯å¾„
        self.vectors_file = self.storage_dir / "prefab_vectors.pkl"
        self.metadata_file = self.storage_dir / "prefab_metadata.json"
        self.index_file = self.storage_dir / "index_info.json"

        # å†…å­˜ä¸­çš„å‘é‡æ•°æ®
        self.vectors = []
        self.documents = []
        self.index_info = {"total_count": 0, "last_updated": None}

        # åŠ è½½å·²æœ‰æ•°æ®
        self._load_data()

    def _load_data(self):
        """ä»æ–‡ä»¶åŠ è½½æ•°æ®"""
        try:
            # åŠ è½½å‘é‡
            if self.vectors_file.exists():
                with open(self.vectors_file, 'rb') as f:
                    self.vectors = pickle.load(f)

            # åŠ è½½å…ƒæ•°æ®
            if self.metadata_file.exists():
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    self.documents = json.load(f)

            # åŠ è½½ç´¢å¼•ä¿¡æ¯
            if self.index_file.exists():
                with open(self.index_file, 'r', encoding='utf-8') as f:
                    self.index_info = json.load(f)

        except Exception as e:
            print(f"âš ï¸ åŠ è½½å‘é‡æ•°æ®å¤±è´¥: {e}")
            self.vectors = []
            self.documents = []
            self.index_info = {"total_count": 0, "last_updated": None}

    def _save_data(self):
        """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            # ä¿å­˜å‘é‡
            with open(self.vectors_file, 'wb') as f:
                pickle.dump(self.vectors, f)

            # ä¿å­˜å…ƒæ•°æ®
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.documents, f, ensure_ascii=False, indent=2)

            # ä¿å­˜ç´¢å¼•ä¿¡æ¯
            self.index_info["last_updated"] = time.strftime("%Y-%m-%d %H:%M:%S")
            with open(self.index_file, 'w', encoding='utf-8') as f:
                json.dump(self.index_info, f, ensure_ascii=False, indent=2)

        except Exception as e:
            print(f"âŒ ä¿å­˜å‘é‡æ•°æ®å¤±è´¥: {e}")

    def clear(self):
        """æ¸…ç©ºæ‰€æœ‰æ•°æ®"""
        self.vectors = []
        self.documents = []
        self.index_info = {"total_count": 0, "last_updated": None}
        self._save_data()

    def add_documents(self, documents: List[Dict[str, Any]], embeddings: List[List[float]]):
        """
        æ·»åŠ æ–‡æ¡£å’Œå¯¹åº”çš„å‘é‡

        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            embeddings: å‘é‡åˆ—è¡¨
        """
        for doc, embedding in zip(documents, embeddings):
            self.documents.append(doc)
            self.vectors.append(np.array(embedding, dtype=np.float32))

        self.index_info["total_count"] = len(self.documents)
        self._save_data()

    def search(self, query_vector: List[float], top_k: int = 5) -> List[Tuple[Dict, float]]:
        """
        å‘é‡ç›¸ä¼¼åº¦æœç´¢

        Args:
            query_vector: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›ç»“æœæ•°é‡

        Returns:
            (æ–‡æ¡£, ç›¸ä¼¼åº¦åˆ†æ•°) çš„åˆ—è¡¨
        """
        if not self.vectors:
            return []

        query_vec = np.array(query_vector, dtype=np.float32)

        # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        similarities = []
        for i, vec in enumerate(self.vectors):
            # ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = np.dot(query_vec, vec) / (np.linalg.norm(query_vec) * np.linalg.norm(vec))
            similarities.append((self.documents[i], float(similarity)))

        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        similarities.sort(key=lambda x: x[1], reverse=True)

        return similarities[:top_k]

    def get_document_by_id(self, doc_id: str) -> Optional[Dict]:
        """æ ¹æ®IDè·å–æ–‡æ¡£"""
        for doc in self.documents:
            if doc.get("id") == doc_id:
                return doc
        return None


class PrefabIndexer:
    """é¢„åˆ¶ä»¶ç´¢å¼•æ„å»ºå™¨ï¼ˆé€‚é…æ™ºè°±AIï¼‰"""

    def __init__(self, timeout: int = 30):
        """
        åˆå§‹åŒ–ç´¢å¼•æ„å»ºå™¨

        Args:
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´
        """
        from gtplanner.utils.config_manager import get_vector_service_config
        from gtplanner.utils.config_manager import get_llm_config

        # è·å–LLMé…ç½®æ¥è·å–APIå¯†é’¥
        llm_config = get_llm_config()
        self.api_key = llm_config.get("api_key")

        self.timeout = timeout

        # ä»é…ç½®è·å–ç´¢å¼•å‚æ•°
        vector_config = get_vector_service_config()
        self.index_name = vector_config.get("prefabs_index_name", "document_gtplanner_prefabs")
        self.vector_field = vector_config.get("vector_field", "combined_text")

        # åˆå§‹åŒ–æœ¬åœ°å‘é‡å­˜å‚¨
        self.vector_store = LocalVectorStore()
    
    def check_vector_service_available(self) -> bool:
        """æ£€æŸ¥æ™ºè°±AIåµŒå…¥æœåŠ¡æ˜¯å¦å¯ç”¨"""
        if not self.api_key:
            print("âŒ æ™ºè°±AI APIå¯†é’¥æœªé…ç½®")
            return False

        try:
            # æ™ºè°±AIåµŒå…¥APIçš„æ ‡å‡†åœ°å€
            embedding_url = "https://open.bigmodel.cn/api/paas/v4/embeddings"

            response = requests.post(
                embedding_url,
                json={
                    "model": "embedding-2",
                    "input": "test"
                },
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.api_key}"
                },
                timeout=5
            )
            if response.status_code == 200:
                print("âœ… æ™ºè°±AIåµŒå…¥æœåŠ¡è¿æ¥æ­£å¸¸")
                return True
            else:
                print(f"âŒ æ™ºè°±AI APIå“åº”å¼‚å¸¸: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ æ™ºè°±AIåµŒå…¥æœåŠ¡è¿æ¥å¤±è´¥: {str(e)}")
            return False

    def _get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        è°ƒç”¨æ™ºè°±AIè·å–æ–‡æœ¬åµŒå…¥

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨

        Returns:
            å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []

        try:
            # æ™ºè°±AIåµŒå…¥APIçš„æ ‡å‡†åœ°å€
            embedding_url = "https://open.bigmodel.cn/api/paas/v4/embeddings"

            response = requests.post(
                embedding_url,
                json={
                    "model": "embedding-2",
                    "input": texts
                },
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.api_key}"
                },
                timeout=self.timeout
            )

            if response.status_code != 200:
                error_msg = f"æ™ºè°±AI APIè°ƒç”¨å¤±è´¥: {response.status_code}, {response.text}"
                print(f"âŒ {error_msg}")
                raise RuntimeError(error_msg)

            result = response.json()
            embeddings = [item["embedding"] for item in result["data"]]
            return embeddings

        except Exception as e:
            print(f"âŒ è·å–åµŒå…¥å¤±è´¥: {str(e)}")
            raise
    
    def load_prefabs_from_json(self, json_path: str = None) -> List[Dict]:
        """
        ä» JSON æ–‡ä»¶åŠ è½½é¢„åˆ¶ä»¶
        
        Args:
            json_path: community-prefabs.json è·¯å¾„
            
        Returns:
            é¢„åˆ¶ä»¶åˆ—è¡¨
        """
        if json_path is None:
            # è‡ªåŠ¨å®šä½
            current_dir = Path(__file__).parent
            json_path = current_dir.parent.parent.parent / "prefabs" / "releases" / "community-prefabs.json"
        
        json_path = Path(json_path)
        if not json_path.exists():
            raise FileNotFoundError(f"Prefabs JSON not found: {json_path}")
        
        with open(json_path, 'r', encoding='utf-8') as f:
            prefabs = json.load(f)
        
        return prefabs
    
    def convert_prefab_to_document(self, prefab: Dict) -> Dict[str, Any]:
        """
        å°†é¢„åˆ¶ä»¶è½¬æ¢ä¸ºå‘é‡æœåŠ¡çš„æ–‡æ¡£æ ¼å¼
        
        Args:
            prefab: é¢„åˆ¶ä»¶å¯¹è±¡ï¼ˆä» community-prefabs.jsonï¼‰
            
        Returns:
            æ–‡æ¡£å¯¹è±¡
        """
        # æ„å»ºæ ‡ç­¾å­—ç¬¦ä¸²
        tags = prefab.get("tags", [])
        tags_str = ", ".join(tags) if tags else ""
        
        # æ„å»ºç»„åˆæ–‡æœ¬ï¼ˆç”¨äº embeddingï¼‰
        combined_text = f"{prefab['name']} {prefab['description']}"
        if tags_str:
            combined_text += f" {tags_str}"
        
        # æ„å»º artifact URL
        artifact_url = self._construct_artifact_url(prefab)
        
        # è¿”å›æ–‡æ¡£å¯¹è±¡
        document = {
            "id": prefab["id"],
            "type": "PREFAB",  # ç»Ÿä¸€ç±»å‹
            "summary": prefab["name"],  # åç§°æ˜ å°„åˆ° summary
            "description": prefab["description"],
            "tags": tags_str,
            "combined_text": combined_text,  # ç”¨äº embedding
            # å…ƒæ•°æ®
            "version": prefab["version"],
            "author": prefab["author"],
            "repo_url": prefab["repo_url"],
            "artifact_url": artifact_url,
            "created_at": time.strftime("%Y-%m-%d %H:%M:%S"),
            "updated_at": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        return document
    
    def _construct_artifact_url(self, prefab: Dict) -> str:
        """
        æ„å»ºé¢„åˆ¶ä»¶çš„ä¸‹è½½é“¾æ¥
        
        æ ¹æ® schema.json è§„åˆ™ï¼š
        {repo_url}/releases/download/v{version}/{id}-{version}.whl
        
        Args:
            prefab: é¢„åˆ¶ä»¶å¯¹è±¡
            
        Returns:
            ä¸‹è½½é“¾æ¥
        """
        repo_url = prefab["repo_url"].rstrip('/')
        version = prefab["version"]
        prefab_id = prefab["id"]
        
        return (
            f"{repo_url}/releases/download/v{version}/{prefab_id}-{version}.whl"
        )
    
    def build_index(
        self,
        json_path: str = None,
        force_reindex: bool = False
    ) -> Dict[str, Any]:
        """
        æ„å»ºé¢„åˆ¶ä»¶ç´¢å¼•

        Args:
            json_path: community-prefabs.json è·¯å¾„
            force_reindex: æ˜¯å¦å¼ºåˆ¶é‡å»ºç´¢å¼•

        Returns:
            ç´¢å¼•æ„å»ºç»“æœ
        """
        start_time = time.time()

        # æ£€æŸ¥æ™ºè°±AIæœåŠ¡
        if not self.check_vector_service_available():
            return {
                "success": False,
                "error": "æ™ºè°±AIåµŒå…¥æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥",
                "index_name": None,
                "indexed_count": 0
            }

        try:
            # 1. åŠ è½½é¢„åˆ¶ä»¶
            prefabs = self.load_prefabs_from_json(json_path)
            print(f"ğŸ“¦ åŠ è½½äº† {len(prefabs)} ä¸ªé¢„åˆ¶ä»¶")

            # 2. å¦‚æœå¼ºåˆ¶é‡å»ºï¼Œå…ˆæ¸…ç©ºç°æœ‰ç´¢å¼•
            if force_reindex:
                self.vector_store.clear()
                print("ğŸ”„ å·²æ¸…ç©ºç°æœ‰ç´¢å¼•")

            # 3. è½¬æ¢ä¸ºæ–‡æ¡£æ ¼å¼
            documents = []
            for prefab in prefabs:
                doc = self.convert_prefab_to_document(prefab)
                documents.append(doc)

            print(f"ğŸ“ è½¬æ¢äº† {len(documents)} ä¸ªæ–‡æ¡£")

            # 4. æ‰¹é‡è·å–åµŒå…¥å‘é‡
            texts = [doc[self.vector_field] for doc in documents]
            print("ğŸ”„ æ­£åœ¨è·å–åµŒå…¥å‘é‡...")

            # åˆ†æ‰¹å¤„ç†ï¼ˆæ™ºè°±AI APIå¯èƒ½æœ‰é•¿åº¦é™åˆ¶ï¼‰
            batch_size = 10
            all_embeddings = []
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i + batch_size]
                batch_embeddings = self._get_embeddings(batch_texts)
                all_embeddings.extend(batch_embeddings)
                print(f"ğŸ“Š å·²å¤„ç† {min(i + batch_size, len(texts))}/{len(texts)} ä¸ªå‘é‡")

            # 5. å­˜å‚¨åˆ°æœ¬åœ°å‘é‡æ•°æ®åº“
            self.vector_store.add_documents(documents, all_embeddings)

            elapsed_time = time.time() - start_time

            return {
                "success": True,
                "index_name": self.index_name,
                "indexed_count": len(documents),
                "elapsed_time": round(elapsed_time, 2),
                "vector_service": "æ™ºè°±AIåµŒå…¥API",
                "local_storage_path": str(self.vector_store.storage_dir)
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "index_name": None,
                "indexed_count": 0
            }
    
    def search_prefabs(self, query: str, top_k: int = 5) -> List[Tuple[Dict, float]]:
        """
        æœç´¢é¢„åˆ¶ä»¶

        Args:
            query: æœç´¢æŸ¥è¯¢
            top_k: è¿”å›ç»“æœæ•°é‡

        Returns:
            (æ–‡æ¡£, ç›¸ä¼¼åº¦åˆ†æ•°) çš„åˆ—è¡¨
        """
        try:
            # è·å–æŸ¥è¯¢å‘é‡
            query_embeddings = self._get_embeddings([query])
            if not query_embeddings:
                return []

            query_vector = query_embeddings[0]

            # åœ¨æœ¬åœ°å‘é‡å­˜å‚¨ä¸­æœç´¢
            results = self.vector_store.search(query_vector, top_k)

            return results

        except Exception as e:
            print(f"âŒ æœç´¢é¢„åˆ¶ä»¶å¤±è´¥: {str(e)}")
            return []

    def get_prefab_by_id(self, prefab_id: str) -> Optional[Dict]:
        """
        æ ¹æ®IDè·å–é¢„åˆ¶ä»¶

        Args:
            prefab_id: é¢„åˆ¶ä»¶ID

        Returns:
            é¢„åˆ¶ä»¶æ–‡æ¡£
        """
        return self.vector_store.get_document_by_id(prefab_id)

    def get_index_info(self) -> Dict[str, Any]:
        """
        è·å–ç´¢å¼•ä¿¡æ¯

        Returns:
            ç´¢å¼•ä¿¡æ¯
        """
        return {
            "index_name": self.index_name,
            "total_count": self.vector_store.index_info["total_count"],
            "last_updated": self.vector_store.index_info["last_updated"],
            "storage_path": str(self.vector_store.storage_dir),
            "vector_service": "æ™ºè°±AIåµŒå…¥API"
        }


# ä¾¿æ·å‡½æ•°
def build_prefab_index(
    json_path: str = None,
    force_reindex: bool = False
) -> Dict[str, Any]:
    """
    æ„å»ºé¢„åˆ¶ä»¶ç´¢å¼•çš„ä¾¿æ·å‡½æ•°

    Args:
        json_path: community-prefabs.json è·¯å¾„
        force_reindex: æ˜¯å¦å¼ºåˆ¶é‡å»º

    Returns:
        ç´¢å¼•æ„å»ºç»“æœ
    """
    indexer = PrefabIndexer()
    return indexer.build_index(json_path, force_reindex)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    result = build_prefab_index(force_reindex=True)
    print(f"\nç´¢å¼•æ„å»ºç»“æœ:")
    print(json.dumps(result, indent=2, ensure_ascii=False))

